[package]
name = "llm-proxy"
version = "0.1.0"
edition = "2024"
authors = [ "Thomas Harmon <thomas.alan.harmon@gmail.com>" ]

[dependencies]
openai-types = { workspace = true }
anthropic-types = { workspace = true }

bytes = { workspace = true, features = ['serde'] }
derive_more = { workspace = true, features = ['as_ref', 'constructor', 'debug', 'deref', 'display', 'from', 'from_str'] }
futures = { workspace = true }
http = { workspace = true }
http-body-util = { workspace = true }
humantime-serde = { workspace = true }
hyper = { workspace = true }
hyper-util = { workspace = true, features = ['server-auto', 'server-graceful', 'tokio'] }
indexmap = { workspace = true, features = ['serde'] }
isocountry = { workspace = true }
reqwest = { workspace = true }
rust_decimal = { workspace = true }
serde = { workspace = true, features = ['derive', 'rc'] }
serde_json = { workspace = true }
serde_with = { workspace = true }
thiserror = { workspace = true }
tokio = { workspace = true }
tower = { workspace = true, features = ['full']}
tower-http = { workspace = true }
tracing = { workspace = true }
tracing-subscriber = { workspace = true, features = ['env-filter', 'std'] }
url = { workspace = true, features = ['serde'] }