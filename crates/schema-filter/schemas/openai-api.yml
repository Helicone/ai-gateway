openapi: 3.0.0
info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  version: 2.3.0
servers:
- url: https://api.openai.com/v1
paths:
  /chat/completions:
    post:
      tags:
      - Chat
      summary: "**Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses) \nto take advantage of the latest OpenAI platform features. Compare\n[Chat Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).\n\n---\n\nCreates a model response for the given chat conversation. Learn more in the\n[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),\nand [audio](/docs/guides/audio) guides.\n\nParameter support can differ depending on the model used to generate the\nresponse, particularly for newer reasoning models. Parameters that are only\nsupported for reasoning models are noted below. For the current state of \nunsupported parameters in reasoning models, \n[refer to the reasoning guide](/docs/guides/reasoning).\n"
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionStreamResponse'
      x-oaiMeta:
        examples:
        - request:
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4o",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new SystemChatMessage("You are a helpful assistant."),
                  new UserChatMessage("Hello!")
              ];

              ChatCompletion completion = client.CompleteChat(messages);

              Console.WriteLine(completion.Content[0].Text);
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "developer",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ]
                }'
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "developer", content: "You are a helpful assistant." }],
                  model: "VAR_chat_model_id",
                  store: true,
                });

                console.log(completion.choices[0]);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "developer", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ]
              )

              print(completion.choices[0].message)
          response: |
            {
              "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
              "object": "chat.completion",
              "created": 1741569952,
              "model": "gpt-4o-2024-08-06",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?",
                    "refusal": null,
                    "annotations": []
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 19,
                "completion_tokens": 10,
                "total_tokens": 29,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "service_tier": "default"
            }
          title: Default
        - request:
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4o",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage(
                  [
                      ChatMessageContentPart.CreateTextPart("What's in this image?"),
                      ChatMessageContentPart.CreateImagePart(new Uri("https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"))
                  ])
              ];

              ChatCompletion completion = client.CompleteChat(messages);

              Console.WriteLine(completion.Content[0].Text);
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4o",
                  "messages": [
                    {
                      "role": "user",
                      "content": [
                        {
                          "type": "text",
                          "text": "What is in this image?"
                        },
                        {
                          "type": "image_url",
                          "image_url": {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                          }
                        }
                      ]
                    }
                  ],
                  "max_tokens": 300
                }'
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.chat.completions.create({
                  model: "gpt-4o",
                  messages: [
                    {
                      role: "user",
                      content: [
                        { type: "text", text: "What's in this image?" },
                        {
                          type: "image_url",
                          image_url: {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                          },
                        }
                      ],
                    },
                  ],
                });
                console.log(response.choices[0]);
              }
              main();
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.chat.completions.create(
                  model="gpt-4o",
                  messages=[
                      {
                          "role": "user",
                          "content": [
                              {"type": "text", "text": "What's in this image?"},
                              {
                                  "type": "image_url",
                                  "image_url": {
                                      "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                                  }
                              },
                          ],
                      }
                  ],
                  max_tokens=300,
              )

              print(response.choices[0])
          response: |
            {
              "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
              "object": "chat.completion",
              "created": 1741570283,
              "model": "gpt-4o-2024-08-06",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
                    "refusal": null,
                    "annotations": []
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 1117,
                "completion_tokens": 46,
                "total_tokens": 1163,
                "prompt_tokens_details": {
                  "cached_tokens": 0,
                  "audio_tokens": 0
                },
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "audio_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "service_tier": "default"
            }
          title: Image input
        - request:
            csharp: |
              using System;
              using System.ClientModel;
              using System.Collections.Generic;
              using System.Threading.Tasks;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4o",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new SystemChatMessage("You are a helpful assistant."),
                  new UserChatMessage("Hello!")
              ];

              AsyncCollectionResult<StreamingChatCompletionUpdate> completionUpdates = client.CompleteChatStreamingAsync(messages);

              await foreach (StreamingChatCompletionUpdate completionUpdate in completionUpdates)
              {
                  if (completionUpdate.ContentUpdate.Count > 0)
                  {
                      Console.Write(completionUpdate.ContentUpdate[0].Text);
                  }
              }
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "developer",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "stream": true
                }'
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  model: "VAR_chat_model_id",
                  messages: [
                    {"role": "developer", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream: true,
                });

                for await (const chunk of completion) {
                  console.log(chunk.choices[0].delta.content);
                }
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "developer", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ],
                stream=True
              )

              for chunk in completion:
                print(chunk.choices[0].delta)
          response: |
            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

            ....

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
          title: Streaming
        - request:
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4o",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              ChatTool getCurrentWeatherTool = ChatTool.CreateFunctionTool(
                  functionName: "get_current_weather",
                  functionDescription: "Get the current weather in a given location",
                  functionParameters: BinaryData.FromString("""
                      {
                          "type": "object",
                          "properties": {
                              "location": {
                                  "type": "string",
                                  "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {
                                  "type": "string",
                                  "enum": [ "celsius", "fahrenheit" ]
                              }
                          },
                          "required": [ "location" ]
                      }
                  """)
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage("What's the weather like in Boston today?"),
              ];

              ChatCompletionOptions options = new()
              {
                  Tools =
                  {
                      getCurrentWeatherTool
                  },
                  ToolChoice = ChatToolChoice.CreateAutoChoice(),
              };

              ChatCompletion completion = client.CompleteChat(messages, options);
            curl: |
              curl https://api.openai.com/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -d '{
                "model": "gpt-4o",
                "messages": [
                  {
                    "role": "user",
                    "content": "What is the weather like in Boston today?"
                  }
                ],
                "tools": [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location"]
                      }
                    }
                  }
                ],
                "tool_choice": "auto"
              }'
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messages = [{"role": "user", "content": "What's the weather like in Boston today?"}];
                const tools = [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                          },
                          "required": ["location"],
                        },
                      }
                    }
                ];

                const response = await openai.chat.completions.create({
                  model: "gpt-4o",
                  messages: messages,
                  tools: tools,
                  tool_choice: "auto",
                });

                console.log(response);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]
              messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]
              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=messages,
                tools=tools,
                tool_choice="auto"
              )

              print(completion)
          response: |
            {
              "id": "chatcmpl-abc123",
              "object": "chat.completion",
              "created": 1699896916,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": null,
                    "tool_calls": [
                      {
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                        }
                      }
                    ]
                  },
                  "logprobs": null,
                  "finish_reason": "tool_calls"
                }
              ],
              "usage": {
                "prompt_tokens": 82,
                "completion_tokens": 17,
                "total_tokens": 99,
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              }
            }
          title: Functions
        - request:
            csharp: |
              using System;
              using System.Collections.Generic;

              using OpenAI.Chat;

              ChatClient client = new(
                  model: "gpt-4o",
                  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY")
              );

              List<ChatMessage> messages =
              [
                  new UserChatMessage("Hello!")
              ];

              ChatCompletionOptions options = new()
              {
                  IncludeLogProbabilities = true,
                  TopLogProbabilityCount = 2
              };

              ChatCompletion completion = client.CompleteChat(messages, options);

              Console.WriteLine(completion.Content[0].Text);
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_chat_model_id",
                  "messages": [
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "logprobs": true,
                  "top_logprobs": 2
                }'
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "user", content: "Hello!" }],
                  model: "VAR_chat_model_id",
                  logprobs: true,
                  top_logprobs: 2,
                });

                console.log(completion.choices[0]);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_chat_model_id",
                messages=[
                  {"role": "user", "content": "Hello!"}
                ],
                logprobs=True,
                top_logprobs=2
              )

              print(completion.choices[0].message)
              print(completion.choices[0].logprobs)
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1702685778,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?"
                  },
                  "logprobs": {
                    "content": [
                      {
                        "token": "Hello",
                        "logprob": -0.31725305,
                        "bytes": [72, 101, 108, 108, 111],
                        "top_logprobs": [
                          {
                            "token": "Hello",
                            "logprob": -0.31725305,
                            "bytes": [72, 101, 108, 108, 111]
                          },
                          {
                            "token": "Hi",
                            "logprob": -1.3190403,
                            "bytes": [72, 105]
                          }
                        ]
                      },
                      {
                        "token": "!",
                        "logprob": -0.02380986,
                        "bytes": [
                          33
                        ],
                        "top_logprobs": [
                          {
                            "token": "!",
                            "logprob": -0.02380986,
                            "bytes": [33]
                          },
                          {
                            "token": " there",
                            "logprob": -3.787621,
                            "bytes": [32, 116, 104, 101, 114, 101]
                          }
                        ]
                      },
                      {
                        "token": " How",
                        "logprob": -0.000054669687,
                        "bytes": [32, 72, 111, 119],
                        "top_logprobs": [
                          {
                            "token": " How",
                            "logprob": -0.000054669687,
                            "bytes": [32, 72, 111, 119]
                          },
                          {
                            "token": "<|end|>",
                            "logprob": -10.953937,
                            "bytes": null
                          }
                        ]
                      },
                      {
                        "token": " can",
                        "logprob": -0.015801601,
                        "bytes": [32, 99, 97, 110],
                        "top_logprobs": [
                          {
                            "token": " can",
                            "logprob": -0.015801601,
                            "bytes": [32, 99, 97, 110]
                          },
                          {
                            "token": " may",
                            "logprob": -4.161023,
                            "bytes": [32, 109, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " I",
                        "logprob": -3.7697225e-6,
                        "bytes": [
                          32,
                          73
                        ],
                        "top_logprobs": [
                          {
                            "token": " I",
                            "logprob": -3.7697225e-6,
                            "bytes": [32, 73]
                          },
                          {
                            "token": " assist",
                            "logprob": -13.596657,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          }
                        ]
                      },
                      {
                        "token": " assist",
                        "logprob": -0.04571125,
                        "bytes": [32, 97, 115, 115, 105, 115, 116],
                        "top_logprobs": [
                          {
                            "token": " assist",
                            "logprob": -0.04571125,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          },
                          {
                            "token": " help",
                            "logprob": -3.1089056,
                            "bytes": [32, 104, 101, 108, 112]
                          }
                        ]
                      },
                      {
                        "token": " you",
                        "logprob": -5.4385737e-6,
                        "bytes": [32, 121, 111, 117],
                        "top_logprobs": [
                          {
                            "token": " you",
                            "logprob": -5.4385737e-6,
                            "bytes": [32, 121, 111, 117]
                          },
                          {
                            "token": " today",
                            "logprob": -12.807695,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " today",
                        "logprob": -0.0040071653,
                        "bytes": [32, 116, 111, 100, 97, 121],
                        "top_logprobs": [
                          {
                            "token": " today",
                            "logprob": -0.0040071653,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          },
                          {
                            "token": "?",
                            "logprob": -5.5247097,
                            "bytes": [63]
                          }
                        ]
                      },
                      {
                        "token": "?",
                        "logprob": -0.0008108172,
                        "bytes": [63],
                        "top_logprobs": [
                          {
                            "token": "?",
                            "logprob": -0.0008108172,
                            "bytes": [63]
                          },
                          {
                            "token": "?\n",
                            "logprob": -7.184561,
                            "bytes": [63, 10]
                          }
                        ]
                      }
                    ]
                  },
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 9,
                "total_tokens": 18,
                "completion_tokens_details": {
                  "reasoning_tokens": 0,
                  "accepted_prediction_tokens": 0,
                  "rejected_prediction_tokens": 0
                }
              },
              "system_fingerprint": null
            }
          title: Logprobs
        group: chat
        name: Create chat completion
        path: create
        returns: |
          Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.
  /completions:
    post:
      tags:
      - Completions
      summary: Creates a completion for the provided prompt and parameters.
      operationId: createCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
      x-oaiMeta:
        examples:
        - request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_completion_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0
                }'
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.completions.create({
                  model: "VAR_completion_model_id",
                  prompt: "Say this is a test.",
                  max_tokens: 7,
                  temperature: 0,
                });

                console.log(completion);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.completions.create(
                model="VAR_completion_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0
              )
          response: |
            {
              "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
              "object": "text_completion",
              "created": 1589478378,
              "model": "VAR_completion_model_id",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [
                {
                  "text": "\n\nThis is indeed a test",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": "length"
                }
              ],
              "usage": {
                "prompt_tokens": 5,
                "completion_tokens": 7,
                "total_tokens": 12
              }
            }
          title: No streaming
        - request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_completion_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0,
                  "stream": true
                }'
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.completions.create({
                  model: "VAR_completion_model_id",
                  prompt: "Say this is a test.",
                  stream: true,
                });

                for await (const chunk of stream) {
                  console.log(chunk.choices[0].text)
                }
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              for chunk in client.completions.create(
                model="VAR_completion_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0,
                stream=True
              ):
                print(chunk.choices[0].text)
          response: |
            {
              "id": "cmpl-7iA7iJjj8V2zOkCGvWF2hAkDWBQZe",
              "object": "text_completion",
              "created": 1690759702,
              "choices": [
                {
                  "text": "This",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": null
                }
              ],
              "model": "gpt-3.5-turbo-instruct"
              "system_fingerprint": "fp_44709d6fcb",
            }
          title: Streaming
        group: completions
        legacy: true
        name: Create completion
        returns: |
          Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.
  /responses:
    post:
      tags:
      - Responses
      summary: |
        Creates a model response. Provide [text](/docs/guides/text) or
        [image](/docs/guides/images) inputs to generate [text](/docs/guides/text)
        or [JSON](/docs/guides/structured-outputs) outputs. Have the model call
        your own [custom code](/docs/guides/function-calling) or use built-in
        [tools](/docs/guides/tools) like [web search](/docs/guides/tools-web-search)
        or [file search](/docs/guides/tools-file-search) to use your own data
        as input for the model's response.
      operationId: createResponse
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateResponse'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Response'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ResponseStreamEvent'
      x-oaiMeta:
        examples:
        - request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4o",
                  "input": "Tell me a three sentence bedtime story about a unicorn."
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4o",
                  input: "Tell me a three sentence bedtime story about a unicorn."
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                model="gpt-4o",
                input="Tell me a three sentence bedtime story about a unicorn."
              )

              print(response)
          response: |
            {
              "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
              "object": "response",
              "created_at": 1741476542,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "In a peaceful grove beneath a silver moon, a unicorn named Lumina discovered a hidden pool that reflected the stars. As she dipped her horn into the water, the pool began to shimmer, revealing a pathway to a magical realm of endless night skies. Filled with wonder, Lumina whispered a wish for all who dream to find their own hidden magic, and as she glanced back, her hoofprints sparkled like stardust.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "generate_summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 36,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 87,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 123
              },
              "user": null,
              "metadata": {}
            }
          title: Text input
        - request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4o",
                  "input": [
                    {
                      "role": "user",
                      "content": [
                        {"type": "input_text", "text": "what is in this image?"},
                        {
                          "type": "input_image",
                          "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                        }
                      ]
                    }
                  ]
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4o",
                  input: [
                      {
                          role: "user",
                          content: [
                              { type: "input_text", text: "what is in this image?" },
                              {
                                  type: "input_image",
                                  image_url:
                                      "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                              },
                          ],
                      },
                  ],
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4o",
                  input=[
                      {
                          "role": "user",
                          "content": [
                              { "type": "input_text", "text": "what is in this image?" },
                              {
                                  "type": "input_image",
                                  "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                              }
                          ]
                      }
                  ]
              )

              print(response)
          response: |
            {
              "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
              "object": "response",
              "created_at": 1741476777,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "generate_summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 328,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 52,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 380
              },
              "user": null,
              "metadata": {}
            }
          title: Image input
        - request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4o",
                  "tools": [{ "type": "web_search_preview" }],
                  "input": "What was a positive news story from today?"
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4o",
                  tools: [{ type: "web_search_preview" }],
                  input: "What was a positive news story from today?",
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4o",
                  tools=[{ "type": "web_search_preview" }],
                  input="What was a positive news story from today?",
              )

              print(response)
          response: |
            {
              "id": "resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c",
              "object": "response",
              "created_at": 1741484430,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "web_search_call",
                  "id": "ws_67ccf18f64008190a39b619f4c8455ef087bb177ab789d5c",
                  "status": "completed"
                },
                {
                  "type": "message",
                  "id": "msg_67ccf190ca3881909d433c50b1f6357e087bb177ab789d5c",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "As of today, March 9, 2025, one notable positive news story...",
                      "annotations": [
                        {
                          "type": "url_citation",
                          "start_index": 442,
                          "end_index": 557,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        },
                        {
                          "type": "url_citation",
                          "start_index": 962,
                          "end_index": 1077,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        },
                        {
                          "type": "url_citation",
                          "start_index": 1336,
                          "end_index": 1451,
                          "url": "https://.../?utm_source=chatgpt.com",
                          "title": "..."
                        }
                      ]
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "generate_summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [
                {
                  "type": "web_search_preview",
                  "domains": [],
                  "search_context_size": "medium",
                  "user_location": {
                    "type": "approximate",
                    "city": null,
                    "country": "US",
                    "region": null,
                    "timezone": null
                  }
                }
              ],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 328,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 356,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 684
              },
              "user": null,
              "metadata": {}
            }
          title: Web search
        - request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4o",
                  "tools": [{
                    "type": "file_search",
                    "vector_store_ids": ["vs_1234567890"],
                    "max_num_results": 20
                  }],
                  "input": "What are the attributes of an ancient brown dragon?"
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4o",
                  tools: [{
                    type: "file_search",
                    vector_store_ids: ["vs_1234567890"],
                    max_num_results: 20
                  }],
                  input: "What are the attributes of an ancient brown dragon?",
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                  model="gpt-4o",
                  tools=[{
                    "type": "file_search",
                    "vector_store_ids": ["vs_1234567890"],
                    "max_num_results": 20
                  }],
                  input="What are the attributes of an ancient brown dragon?",
              )

              print(response)
          response: |
            {
              "id": "resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7",
              "object": "response",
              "created_at": 1741485253,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "file_search_call",
                  "id": "fs_67ccf4c63cd08190887ef6464ba5681609504fb6872380d7",
                  "status": "completed",
                  "queries": [
                    "attributes of an ancient brown dragon"
                  ],
                  "results": null
                },
                {
                  "type": "message",
                  "id": "msg_67ccf4c93e5c81909d595b369351a9d309504fb6872380d7",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "The attributes of an ancient brown dragon include...",
                      "annotations": [
                        {
                          "type": "file_citation",
                          "index": 320,
                          "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                          "filename": "dragons.pdf"
                        },
                        {
                          "type": "file_citation",
                          "index": 576,
                          "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                          "filename": "dragons.pdf"
                        },
                        {
                          "type": "file_citation",
                          "index": 815,
                          "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                          "filename": "dragons.pdf"
                        },
                        {
                          "type": "file_citation",
                          "index": 815,
                          "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                          "filename": "dragons.pdf"
                        },
                        {
                          "type": "file_citation",
                          "index": 1030,
                          "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                          "filename": "dragons.pdf"
                        },
                        {
                          "type": "file_citation",
                          "index": 1030,
                          "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                          "filename": "dragons.pdf"
                        },
                        {
                          "type": "file_citation",
                          "index": 1156,
                          "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                          "filename": "dragons.pdf"
                        },
                        {
                          "type": "file_citation",
                          "index": 1225,
                          "file_id": "file-4wDz5b167pAf72nx1h9eiN",
                          "filename": "dragons.pdf"
                        }
                      ]
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "generate_summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [
                {
                  "type": "file_search",
                  "filters": null,
                  "max_num_results": 20,
                  "ranking_options": {
                    "ranker": "auto",
                    "score_threshold": 0.0
                  },
                  "vector_store_ids": [
                    "vs_1234567890"
                  ]
                }
              ],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 18307,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 348,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 18655
              },
              "user": null,
              "metadata": {}
            }
          title: File search
        - request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4o",
                  "instructions": "You are a helpful assistant.",
                  "input": "Hello!",
                  "stream": true
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "gpt-4o",
                  instructions: "You are a helpful assistant.",
                  input: "Hello!",
                  stream: true,
              });

              for await (const event of response) {
                  console.log(event);
              }
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.responses.create(
                model="gpt-4o",
                instructions="You are a helpful assistant.",
                input="Hello!",
                stream=True
              )

              for event in response:
                print(event)
          response: |
            event: response.created
            data: {"type":"response.created","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4o-2024-08-06","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"generate_summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

            event: response.in_progress
            data: {"type":"response.in_progress","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4o-2024-08-06","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"generate_summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

            event: response.output_item.added
            data: {"type":"response.output_item.added","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"in_progress","role":"assistant","content":[]}}

            event: response.content_part.added
            data: {"type":"response.content_part.added","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"","annotations":[]}}

            event: response.output_text.delta
            data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"Hi"}

            ...

            event: response.output_text.done
            data: {"type":"response.output_text.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"text":"Hi there! How can I assist you today?"}

            event: response.content_part.done
            data: {"type":"response.content_part.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}}

            event: response.output_item.done
            data: {"type":"response.output_item.done","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}]}}

            event: response.completed
            data: {"type":"response.completed","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"completed","error":null,"incomplete_details":null,"instructions":"You are a helpful assistant.","max_output_tokens":null,"model":"gpt-4o-2024-08-06","output":[{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"Hi there! How can I assist you today?","annotations":[]}]}],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"generate_summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":{"input_tokens":37,"output_tokens":11,"output_tokens_details":{"reasoning_tokens":0},"total_tokens":48},"user":null,"metadata":{}}}
          title: Streaming
        - request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4o",
                  "input": "What is the weather like in Boston today?",
                  "tools": [
                    {
                      "type": "function",
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location", "unit"]
                      }
                    }
                  ],
                  "tool_choice": "auto"
                }'
            javascript: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                      type: "function",
                      name: "get_current_weather",
                      description: "Get the current weather in a given location",
                      parameters: {
                          type: "object",
                          properties: {
                              location: {
                                  type: "string",
                                  description: "The city and state, e.g. San Francisco, CA",
                              },
                              unit: { type: "string", enum: ["celsius", "fahrenheit"] },
                          },
                          required: ["location", "unit"],
                      },
                  },
              ];

              const response = await openai.responses.create({
                  model: "gpt-4o",
                  tools: tools,
                  input: "What is the weather like in Boston today?",
                  tool_choice: "auto",
              });

              console.log(response);
            python: |
              from openai import OpenAI

              client = OpenAI()

              tools = [
                  {
                      "type": "function",
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {
                                "type": "string",
                                "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location", "unit"],
                      }
                  }
              ]

              response = client.responses.create(
                model="gpt-4o",
                tools=tools,
                input="What is the weather like in Boston today?",
                tool_choice="auto"
              )

              print(response)
          response: |
            {
              "id": "resp_67ca09c5efe0819096d0511c92b8c890096610f474011cc0",
              "object": "response",
              "created_at": 1741294021,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "function_call",
                  "id": "fc_67ca09c6bedc8190a7abfec07b1a1332096610f474011cc0",
                  "call_id": "call_unLAR8MvFNptuiZK6K6HCy5k",
                  "name": "get_current_weather",
                  "arguments": "{\"location\":\"Boston, MA\",\"unit\":\"celsius\"}",
                  "status": "completed"
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "generate_summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [
                {
                  "type": "function",
                  "description": "Get the current weather in a given location",
                  "name": "get_current_weather",
                  "parameters": {
                    "type": "object",
                    "properties": {
                      "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA"
                      },
                      "unit": {
                        "type": "string",
                        "enum": [
                          "celsius",
                          "fahrenheit"
                        ]
                      }
                    },
                    "required": [
                      "location",
                      "unit"
                    ]
                  },
                  "strict": true
                }
              ],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 291,
                "output_tokens": 23,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 314
              },
              "user": null,
              "metadata": {}
            }
          title: Functions
        - request:
            curl: |
              curl https://api.openai.com/v1/responses \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "o3-mini",
                  "input": "How much wood would a woodchuck chuck?",
                  "reasoning": {
                    "effort": "high"
                  }
                }'
            javascript: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              const response = await openai.responses.create({
                  model: "o3-mini",
                  input: "How much wood would a woodchuck chuck?",
                  reasoning: {
                    effort: "high"
                  }
              });

              console.log(response);
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.responses.create(
                  model="o3-mini",
                  input="How much wood would a woodchuck chuck?",
                  reasoning={
                      "effort": "high"
                  }
              )

              print(response)
          response: |
            {
              "id": "resp_67ccd7eca01881908ff0b5146584e408072912b2993db808",
              "object": "response",
              "created_at": 1741477868,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "o1-2024-12-17",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "The classic tongue twister...",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": "high",
                "generate_summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 81,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 1035,
                "output_tokens_details": {
                  "reasoning_tokens": 832
                },
                "total_tokens": 1116
              },
              "user": null,
              "metadata": {}
            }
          title: Reasoning
        group: responses
        name: Create a model response
        path: create
        returns: |
          Returns a [Response](/docs/api-reference/responses/object) object.
components:
  schemas:
    Annotation:
      oneOf:
      - $ref: '#/components/schemas/FileCitation'
      - $ref: '#/components/schemas/UrlCitation'
      - $ref: '#/components/schemas/FilePath'
    ChatCompletionFunctionCallOption:
      description: |
        Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.
      type: object
      properties:
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
    ChatCompletionFunctions:
      deprecated: true
      type: object
      properties:
        description:
          description: A description of what the function does, used by the model to choose when and how to call the function.
          type: string
        name:
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
          type: string
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
      required:
      - name
    ChatCompletionMessageToolCall:
      type: object
      properties:
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of the tool. Currently, only `function` is supported.
          x-stainless-const: true
          type: string
          enum:
          - function
        function:
          description: The function that the model called.
          type: object
          properties:
            name:
              description: The name of the function to call.
              type: string
            arguments:
              description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
              type: string
          required:
          - name
          - arguments
      required:
      - id
      - type
      - function
    ChatCompletionMessageToolCallChunk:
      type: object
      properties:
        index:
          type: integer
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of the tool. Currently, only `function` is supported.
          x-stainless-const: true
          type: string
          enum:
          - function
        function:
          type: object
          properties:
            name:
              description: The name of the function to call.
              type: string
            arguments:
              description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
              type: string
      required:
      - index
    ChatCompletionMessageToolCalls:
      description: The tool calls generated by the model, such as function calls.
      type: array
      items:
        $ref: '#/components/schemas/ChatCompletionMessageToolCall'
    ChatCompletionNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to call a specific function.
      type: object
      properties:
        type:
          description: The type of the tool. Currently, only `function` is supported.
          x-stainless-const: true
          type: string
          enum:
          - function
        function:
          type: object
          properties:
            name:
              description: The name of the function to call.
              type: string
          required:
          - name
      required:
      - type
      - function
    ChatCompletionRequestAssistantMessage:
      title: Assistant message
      description: |
        Messages sent by the model in response to user messages.
      type: object
      properties:
        content:
          nullable: true
          description: |
            The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
          x-oaiExpandable: true
          oneOf:
          - title: Text content
            description: The contents of the assistant message.
            type: string
          - title: Array of content parts
            description: An array of content parts with a defined type. Can be one or more of type `text`, or exactly one of type `refusal`.
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageContentPart'
            minItems: 1
        refusal:
          nullable: true
          description: The refusal message by the assistant.
          type: string
        role:
          description: The role of the messages author, in this case `assistant`.
          x-stainless-const: true
          type: string
          enum:
          - assistant
        name:
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
          type: string
        audio:
          nullable: true
          description: "Data about a previous audio response from the model. \n[Learn more](/docs/guides/audio).\n"
          x-oaiExpandable: true
          type: object
          properties:
            id:
              description: |
                Unique identifier for a previous audio response from the model.
              type: string
          required:
          - id
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
        function_call:
          nullable: true
          deprecated: true
          description: Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.
          type: object
          properties:
            arguments:
              description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
              type: string
            name:
              description: The name of the function to call.
              type: string
          required:
          - arguments
          - name
      required:
      - role
    ChatCompletionRequestAssistantMessageContentPart:
      x-oaiExpandable: true
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartRefusal'
    ChatCompletionRequestDeveloperMessage:
      title: Developer message
      description: |
        Developer-provided instructions that the model should follow, regardless of
        messages sent by the user. With o1 models and newer, `developer` messages
        replace the previous `system` messages.
      type: object
      properties:
        content:
          description: The contents of the developer message.
          oneOf:
          - title: Text content
            description: The contents of the developer message.
            type: string
          - title: Array of content parts
            description: An array of content parts with a defined type. For developer messages, only type `text` is supported.
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
            minItems: 1
        role:
          description: The role of the messages author, in this case `developer`.
          x-stainless-const: true
          type: string
          enum:
          - developer
        name:
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
    ChatCompletionRequestFunctionMessage:
      deprecated: true
      title: Function message
      type: object
      properties:
        role:
          description: The role of the messages author, in this case `function`.
          x-stainless-const: true
          type: string
          enum:
          - function
        content:
          nullable: true
          description: The contents of the function message.
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - role
      - content
      - name
    ChatCompletionRequestMessage:
      x-oaiExpandable: true
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestDeveloperMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
    ChatCompletionRequestMessageContentPartAudio:
      title: Audio content part
      description: |
        Learn about [audio inputs](/docs/guides/audio).
      type: object
      properties:
        type:
          description: The type of the content part. Always `input_audio`.
          x-stainless-const: true
          type: string
          enum:
          - input_audio
        input_audio:
          type: object
          properties:
            data:
              description: Base64 encoded audio data.
              type: string
            format:
              description: |
                The format of the encoded audio data. Currently supports "wav" and "mp3".
              type: string
              enum:
              - wav
              - mp3
          required:
          - data
          - format
      required:
      - type
      - input_audio
    ChatCompletionRequestMessageContentPartFile:
      title: File content part
      description: |
        Learn about [file inputs](/docs/guides/text) for text generation.
      type: object
      properties:
        type:
          description: The type of the content part. Always `file`.
          x-stainless-const: true
          type: string
          enum:
          - file
        file:
          type: object
          properties:
            filename:
              description: "The name of the file, used when passing the file to the model as a \nstring.\n"
              type: string
            file_data:
              description: "The base64 encoded file data, used when passing the file to the model \nas a string.\n"
              type: string
            file_id:
              description: |
                The ID of an uploaded file to use as input.
              type: string
      required:
      - type
      - file
    ChatCompletionRequestMessageContentPartImage:
      title: Image content part
      description: |
        Learn about [image inputs](/docs/guides/vision).
      type: object
      properties:
        type:
          description: The type of the content part.
          x-stainless-const: true
          type: string
          enum:
          - image_url
        image_url:
          type: object
          properties:
            url:
              description: Either a URL of the image or the base64 encoded image data.
              type: string
              format: uri
            detail:
              description: Specifies the detail level of the image. Learn more in the [Vision guide](/docs/guides/vision#low-or-high-fidelity-image-understanding).
              default: auto
              type: string
              enum:
              - auto
              - low
              - high
          required:
          - url
      required:
      - type
      - image_url
    ChatCompletionRequestMessageContentPartRefusal:
      title: Refusal content part
      type: object
      properties:
        type:
          description: The type of the content part.
          x-stainless-const: true
          type: string
          enum:
          - refusal
        refusal:
          description: The refusal message generated by the model.
          type: string
      required:
      - type
      - refusal
    ChatCompletionRequestMessageContentPartText:
      title: Text content part
      description: |
        Learn about [text inputs](/docs/guides/text-generation).
      type: object
      properties:
        type:
          description: The type of the content part.
          x-stainless-const: true
          type: string
          enum:
          - text
        text:
          description: The text content.
          type: string
      required:
      - type
      - text
    ChatCompletionRequestSystemMessage:
      title: System message
      description: |
        Developer-provided instructions that the model should follow, regardless of
        messages sent by the user. With o1 models and newer, use `developer` messages
        for this purpose instead.
      type: object
      properties:
        content:
          description: The contents of the system message.
          oneOf:
          - title: Text content
            description: The contents of the system message.
            type: string
          - title: Array of content parts
            description: An array of content parts with a defined type. For system messages, only type `text` is supported.
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionRequestSystemMessageContentPart'
            minItems: 1
        role:
          description: The role of the messages author, in this case `system`.
          x-stainless-const: true
          type: string
          enum:
          - system
        name:
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
    ChatCompletionRequestSystemMessageContentPart:
      x-oaiExpandable: true
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
    ChatCompletionRequestToolMessage:
      title: Tool message
      type: object
      properties:
        role:
          description: The role of the messages author, in this case `tool`.
          x-stainless-const: true
          type: string
          enum:
          - tool
        content:
          description: The contents of the tool message.
          oneOf:
          - title: Text content
            description: The contents of the tool message.
            type: string
          - title: Array of content parts
            description: An array of content parts with a defined type. For tool messages, only type `text` is supported.
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionRequestToolMessageContentPart'
            minItems: 1
        tool_call_id:
          description: Tool call that this message is responding to.
          type: string
      required:
      - role
      - content
      - tool_call_id
    ChatCompletionRequestToolMessageContentPart:
      x-oaiExpandable: true
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
    ChatCompletionRequestUserMessage:
      title: User message
      description: |
        Messages sent by an end user, containing prompts or additional context
        information.
      type: object
      properties:
        content:
          description: |
            The contents of the user message.
          x-oaiExpandable: true
          oneOf:
          - title: Text content
            description: The text contents of the message.
            type: string
          - title: Array of content parts
            description: An array of content parts with a defined type. Supported options differ based on the [model](/docs/models) being used to generate the response. Can contain text, image, or audio inputs.
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionRequestUserMessageContentPart'
            minItems: 1
        role:
          description: The role of the messages author, in this case `user`.
          x-stainless-const: true
          type: string
          enum:
          - user
        name:
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
    ChatCompletionRequestUserMessageContentPart:
      x-oaiExpandable: true
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartAudio'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartFile'
    ChatCompletionResponseMessage:
      description: A chat completion message generated by the model.
      type: object
      properties:
        content:
          nullable: true
          description: The contents of the message.
          type: string
        refusal:
          nullable: true
          description: The refusal message generated by the model.
          type: string
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
        annotations:
          description: |
            Annotations for the message, when applicable, as when using the
            [web search tool](/docs/guides/tools-web-search?api-mode=chat).
          type: array
          items:
            description: |
              A URL citation when using web search.
            type: object
            properties:
              type:
                description: The type of the URL citation. Always `url_citation`.
                x-stainless-const: true
                type: string
                enum:
                - url_citation
              url_citation:
                description: A URL citation when using web search.
                type: object
                properties:
                  end_index:
                    description: The index of the last character of the URL citation in the message.
                    type: integer
                  start_index:
                    description: The index of the first character of the URL citation in the message.
                    type: integer
                  url:
                    description: The URL of the web resource.
                    type: string
                  title:
                    description: The title of the web resource.
                    type: string
                required:
                - end_index
                - start_index
                - url
                - title
            required:
            - type
            - url_citation
        role:
          description: The role of the author of this message.
          x-stainless-const: true
          type: string
          enum:
          - assistant
        function_call:
          deprecated: true
          description: Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.
          type: object
          properties:
            arguments:
              description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
              type: string
            name:
              description: The name of the function to call.
              type: string
          required:
          - name
          - arguments
        audio:
          nullable: true
          description: |
            If the audio output modality is requested, this object contains data
            about the audio response from the model. [Learn more](/docs/guides/audio).
          x-oaiExpandable: true
          type: object
          properties:
            id:
              description: Unique identifier for this audio response.
              type: string
            expires_at:
              description: |
                The Unix timestamp (in seconds) for when this audio response will
                no longer be accessible on the server for use in multi-turn
                conversations.
              type: integer
            data:
              description: |
                Base64 encoded audio bytes generated by the model, in the format
                specified in the request.
              type: string
            transcript:
              description: Transcript of the audio generated by the model.
              type: string
          required:
          - id
          - expires_at
          - data
          - transcript
      required:
      - role
      - content
      - refusal
    ChatCompletionStreamOptions:
      nullable: true
      description: |
        Options for streaming response. Only set this when you set `stream: true`.
      type: object
      properties:
        include_usage:
          description: "If set, an additional chunk will be streamed before the `data: [DONE]`\nmessage. The `usage` field on this chunk shows the token usage statistics\nfor the entire request, and the `choices` field will always be an empty\narray. \n\nAll other chunks will also include a `usage` field, but with a null\nvalue. **NOTE:** If the stream is interrupted, you may not receive the\nfinal usage chunk which contains the total token usage for the request.\n"
          type: boolean
    ChatCompletionStreamResponseDelta:
      description: A chat completion delta generated by streamed model responses.
      type: object
      properties:
        content:
          nullable: true
          description: The contents of the chunk message.
          type: string
        function_call:
          deprecated: true
          description: Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.
          type: object
          properties:
            arguments:
              description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
              type: string
            name:
              description: The name of the function to call.
              type: string
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk'
        role:
          description: The role of the author of this message.
          type: string
          enum:
          - developer
          - system
          - user
          - assistant
          - tool
        refusal:
          nullable: true
          description: The refusal message generated by the model.
          type: string
    ChatCompletionTokenLogprob:
      type: object
      properties:
        token:
          description: The token.
          type: string
        logprob:
          description: The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
          type: number
        bytes:
          nullable: true
          description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
          type: array
          items:
            type: integer
        top_logprobs:
          description: List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.
          type: array
          items:
            type: object
            properties:
              token:
                description: The token.
                type: string
              logprob:
                description: The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely.
                type: number
              bytes:
                nullable: true
                description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
                type: array
                items:
                  type: integer
            required:
            - token
            - logprob
            - bytes
      required:
      - token
      - logprob
      - bytes
      - top_logprobs
    ChatCompletionTool:
      type: object
      properties:
        type:
          description: The type of the tool. Currently, only `function` is supported.
          x-stainless-const: true
          type: string
          enum:
          - function
        function:
          $ref: '#/components/schemas/FunctionObject'
      required:
      - type
      - function
    ChatCompletionToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tool and instead generates a message.
        `auto` means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools.
        Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

        `none` is the default when no tools are present. `auto` is the default if tools are present.
      x-oaiExpandable: true
      oneOf:
      - description: |
          `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools.
        type: string
        enum:
        - none
        - auto
        - required
      - $ref: '#/components/schemas/ChatCompletionNamedToolChoice'
    Click:
      title: Click
      description: |
        A click action.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a click action, this property is \nalways set to `click`.\n"
          default: click
          x-stainless-const: true
          type: string
          enum:
          - click
        button:
          description: |
            Indicates which mouse button was pressed during the click. One of `left`, `right`, `wheel`, `back`, or `forward`.
          type: string
          enum:
          - left
          - right
          - wheel
          - back
          - forward
        x:
          description: |
            The x-coordinate where the click occurred.
          type: integer
        y:
          description: |
            The y-coordinate where the click occurred.
          type: integer
      required:
      - type
      - button
      - x
      - y
    CodeInterpreterFileOutput:
      title: Code interpreter file output
      description: |
        The output of a code interpreter tool call that is a file.
      type: object
      properties:
        type:
          description: |
            The type of the code interpreter file output. Always `files`.
          x-stainless-const: true
          type: string
          enum:
          - files
        files:
          type: array
          items:
            type: object
            properties:
              mime_type:
                description: |
                  The MIME type of the file.
                type: string
              file_id:
                description: |
                  The ID of the file.
                type: string
            required:
            - mime_type
            - file_id
      required:
      - type
      - files
    CodeInterpreterTextOutput:
      title: Code interpreter text output
      description: |
        The output of a code interpreter tool call that is text.
      type: object
      properties:
        type:
          description: |
            The type of the code interpreter text output. Always `logs`.
          x-stainless-const: true
          type: string
          enum:
          - logs
        logs:
          description: |
            The logs of the code interpreter tool call.
          type: string
      required:
      - type
      - logs
    CodeInterpreterToolCall:
      title: Code interpreter tool call
      description: |
        A tool call to run code.
      type: object
      properties:
        id:
          description: |
            The unique ID of the code interpreter tool call.
          type: string
        type:
          description: |
            The type of the code interpreter tool call. Always `code_interpreter_call`.
          x-stainless-const: true
          type: string
          enum:
          - code_interpreter_call
        code:
          description: |
            The code to run.
          type: string
        status:
          description: |
            The status of the code interpreter tool call.
          type: string
          enum:
          - in_progress
          - interpreting
          - completed
        results:
          description: |
            The results of the code interpreter tool call.
          type: array
          items:
            $ref: '#/components/schemas/CodeInterpreterToolOutput'
      required:
      - id
      - type
      - code
      - status
      - results
    CodeInterpreterToolOutput:
      oneOf:
      - $ref: '#/components/schemas/CodeInterpreterTextOutput'
      - $ref: '#/components/schemas/CodeInterpreterFileOutput'
    ComparisonFilter:
      title: Comparison Filter
      description: |
        A filter used to compare a specified attribute key to a given value using a defined comparison operation.
      x-oaiMeta:
        name: ComparisonFilter
      type: object
      properties:
        type:
          description: |
            Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`.
            - `eq`: equals
            - `ne`: not equal
            - `gt`: greater than
            - `gte`: greater than or equal
            - `lt`: less than
            - `lte`: less than or equal
          default: eq
          type: string
          enum:
          - eq
          - ne
          - gt
          - gte
          - lt
          - lte
        key:
          description: The key to compare against the value.
          type: string
        value:
          description: The value to compare against the attribute key; supports string, number, or boolean types.
          oneOf:
          - type: string
          - type: number
          - type: boolean
      required:
      - type
      - key
      - value
      additionalProperties: false
    CompletionUsage:
      description: Usage statistics for the completion request.
      type: object
      properties:
        completion_tokens:
          description: Number of tokens in the generated completion.
          default: 0
          type: integer
        prompt_tokens:
          description: Number of tokens in the prompt.
          default: 0
          type: integer
        total_tokens:
          description: Total number of tokens used in the request (prompt + completion).
          default: 0
          type: integer
        completion_tokens_details:
          description: Breakdown of tokens used in a completion.
          type: object
          properties:
            accepted_prediction_tokens:
              description: |
                When using Predicted Outputs, the number of tokens in the
                prediction that appeared in the completion.
              default: 0
              type: integer
            audio_tokens:
              description: Audio input tokens generated by the model.
              default: 0
              type: integer
            reasoning_tokens:
              description: Tokens generated by the model for reasoning.
              default: 0
              type: integer
            rejected_prediction_tokens:
              description: |
                When using Predicted Outputs, the number of tokens in the
                prediction that did not appear in the completion. However, like
                reasoning tokens, these tokens are still counted in the total
                completion tokens for purposes of billing, output, and context window
                limits.
              default: 0
              type: integer
        prompt_tokens_details:
          description: Breakdown of tokens used in the prompt.
          type: object
          properties:
            audio_tokens:
              description: Audio input tokens present in the prompt.
              default: 0
              type: integer
            cached_tokens:
              description: Cached tokens present in the prompt.
              default: 0
              type: integer
      required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
    CompoundFilter:
      title: Compound Filter
      description: Combine multiple filters using `and` or `or`.
      x-oaiMeta:
        name: CompoundFilter
      type: object
      properties:
        type:
          description: 'Type of operation: `and` or `or`.'
          type: string
          enum:
          - and
          - or
        filters:
          description: Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.
          type: array
          items:
            oneOf:
            - $ref: '#/components/schemas/ComparisonFilter'
            - type: object
              additionalProperties: true
      required:
      - type
      - filters
      additionalProperties: false
    ComputerAction:
      oneOf:
      - $ref: '#/components/schemas/Click'
      - $ref: '#/components/schemas/DoubleClick'
      - $ref: '#/components/schemas/Drag'
      - $ref: '#/components/schemas/KeyPress'
      - $ref: '#/components/schemas/Move'
      - $ref: '#/components/schemas/Screenshot'
      - $ref: '#/components/schemas/Scroll'
      - $ref: '#/components/schemas/Type'
      - $ref: '#/components/schemas/Wait'
    ComputerTool:
      title: Computer use
      description: "A tool that controls a virtual computer. Learn more about the \n[computer tool](/docs/guides/tools-computer-use).\n"
      type: object
      properties:
        type:
          description: |
            The type of the computer use tool. Always `computer_use_preview`.
          x-stainless-const: true
          type: string
          enum:
          - computer_use_preview
        display_width:
          description: |
            The width of the computer display.
          type: number
        display_height:
          description: |
            The height of the computer display.
          type: number
        environment:
          description: |
            The type of computer environment to control.
          type: string
          enum:
          - mac
          - windows
          - ubuntu
          - browser
      required:
      - type
      - display_width
      - display_height
      - environment
    ComputerToolCall:
      title: Computer tool call
      description: "A tool call to a computer use tool. See the \n[computer use guide](/docs/guides/tools-computer-use) for more information.\n"
      type: object
      properties:
        type:
          description: The type of the computer call. Always `computer_call`.
          default: computer_call
          type: string
          enum:
          - computer_call
        id:
          description: The unique ID of the computer call.
          type: string
        call_id:
          description: |
            An identifier used when responding to the tool call with output.
          type: string
        action:
          $ref: '#/components/schemas/ComputerAction'
        pending_safety_checks:
          description: |
            The pending safety checks for the computer call.
          x-oaiExpandable: true
          type: array
          items:
            $ref: '#/components/schemas/ComputerToolCallSafetyCheck'
        status:
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API.
          type: string
          enum:
          - in_progress
          - completed
          - incomplete
      required:
      - type
      - id
      - action
      - call_id
      - pending_safety_checks
      - status
    ComputerToolCallSafetyCheck:
      description: |
        A pending safety check for the computer call.
      type: object
      properties:
        id:
          description: The ID of the pending safety check.
          type: string
        code:
          description: The type of the pending safety check.
          type: string
        message:
          description: Details about the pending safety check.
          type: string
      required:
      - id
      - code
      - message
    Coordinate:
      title: Coordinate
      description: |
        An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.
      type: object
      properties:
        x:
          description: |
            The x-coordinate.
          type: integer
        y:
          description: |
            The y-coordinate.
          type: integer
      required:
      - x
      - y
    CreateChatCompletionRequest:
      allOf:
      - $ref: '#/components/schemas/CreateModelResponseProperties'
      - type: object
        properties:
          messages:
            description: |
              A list of messages comprising the conversation so far. Depending on the
              [model](/docs/models) you use, different message types (modalities) are
              supported, like [text](/docs/guides/text-generation),
              [images](/docs/guides/vision), and [audio](/docs/guides/audio).
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionRequestMessage'
            minItems: 1
          model:
            $ref: '#/components/schemas/ModelIdsShared'
          modalities:
            $ref: '#/components/schemas/ResponseModalities'
          reasoning_effort:
            $ref: '#/components/schemas/ReasoningEffort'
          max_completion_tokens:
            nullable: true
            description: |
              An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).
            type: integer
          frequency_penalty:
            nullable: true
            description: |
              Number between -2.0 and 2.0. Positive values penalize new tokens based on
              their existing frequency in the text so far, decreasing the model's
              likelihood to repeat the same line verbatim.
            default: 0
            type: number
            minimum: -2.0
            maximum: 2.0
          presence_penalty:
            nullable: true
            description: |
              Number between -2.0 and 2.0. Positive values penalize new tokens based on
              whether they appear in the text so far, increasing the model's likelihood
              to talk about new topics.
            default: 0
            type: number
            minimum: -2.0
            maximum: 2.0
          web_search_options:
            title: Web search
            description: |
              This tool searches the web for relevant results to use in a response.
              Learn more about the [web search tool](/docs/guides/tools-web-search?api-mode=chat).
            type: object
            properties:
              user_location:
                nullable: true
                description: |
                  Approximate location parameters for the search.
                type: object
                properties:
                  type:
                    description: |
                      The type of location approximation. Always `approximate`.
                    x-stainless-const: true
                    type: string
                    enum:
                    - approximate
                  approximate:
                    $ref: '#/components/schemas/WebSearchLocation'
                required:
                - type
                - approximate
              search_context_size:
                $ref: '#/components/schemas/WebSearchContextSize'
          top_logprobs:
            nullable: true
            description: |
              An integer between 0 and 20 specifying the number of most likely tokens to
              return at each token position, each with an associated log probability.
              `logprobs` must be set to `true` if this parameter is used.
            type: integer
            minimum: 0
            maximum: 20
          response_format:
            description: |
              An object specifying the format that the model must output.

              Setting to `{ "type": "json_schema", "json_schema": {...} }` enables
              Structured Outputs which ensures the model will match your supplied JSON
              schema. Learn more in the [Structured Outputs
              guide](/docs/guides/structured-outputs).

              Setting to `{ "type": "json_object" }` enables the older JSON mode, which
              ensures the message the model generates is valid JSON. Using `json_schema`
              is preferred for models that support it.
            x-oaiExpandable: true
            oneOf:
            - $ref: '#/components/schemas/ResponseFormatText'
            - $ref: '#/components/schemas/ResponseFormatJsonSchema'
            - $ref: '#/components/schemas/ResponseFormatJsonObject'
          service_tier:
            nullable: true
            description: |
              Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:
                - If set to 'auto', and the Project is Scale tier enabled, the system
                  will utilize scale tier credits until they are exhausted.
                - If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
                - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
                - When not set, the default behavior is 'auto'.

                When this parameter is set, the response body will include the `service_tier` utilized.
            default: auto
            type: string
            enum:
            - auto
            - default
          audio:
            nullable: true
            description: |
              Parameters for audio output. Required when audio output is requested with
              `modalities: ["audio"]`. [Learn more](/docs/guides/audio).
            x-oaiExpandable: true
            type: object
            properties:
              voice:
                $ref: '#/components/schemas/VoiceIdsShared'
              format:
                description: |
                  Specifies the output audio format. Must be one of `wav`, `mp3`, `flac`,
                  `opus`, or `pcm16`.
                type: string
                enum:
                - wav
                - mp3
                - flac
                - opus
                - pcm16
            required:
            - voice
            - format
          store:
            nullable: true
            description: "Whether or not to store the output of this chat completion request for \nuse in our [model distillation](/docs/guides/distillation) or\n[evals](/docs/guides/evals) products.\n"
            default: false
            type: boolean
          stream:
            nullable: true
            description: |
              If set to true, the model response data will be streamed to the client
              as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).
              See the [Streaming section below](/docs/api-reference/chat/streaming)
              for more information, along with the [streaming responses](/docs/guides/streaming-responses)
              guide for more information on how to handle the streaming events.
            default: false
            type: boolean
          stop:
            $ref: '#/components/schemas/StopConfiguration'
          logit_bias:
            nullable: true
            description: |
              Modify the likelihood of specified tokens appearing in the completion.

              Accepts a JSON object that maps tokens (specified by their token ID in the
              tokenizer) to an associated bias value from -100 to 100. Mathematically,
              the bias is added to the logits generated by the model prior to sampling.
              The exact effect will vary per model, but values between -1 and 1 should
              decrease or increase likelihood of selection; values like -100 or 100
              should result in a ban or exclusive selection of the relevant token.
            x-oaiTypeLabel: map
            type: object
            additionalProperties:
              type: integer
          logprobs:
            nullable: true
            description: |
              Whether to return log probabilities of the output tokens or not. If true,
              returns the log probabilities of each output token returned in the
              `content` of `message`.
            default: false
            type: boolean
          max_tokens:
            nullable: true
            deprecated: true
            description: |
              The maximum number of [tokens](/tokenizer) that can be generated in the
              chat completion. This value can be used to control
              [costs](https://openai.com/api/pricing/) for text generated via API.

              This value is now deprecated in favor of `max_completion_tokens`, and is
              not compatible with [o1 series models](/docs/guides/reasoning).
            type: integer
          n:
            nullable: true
            example: 1
            description: How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
            default: 1
            type: integer
            minimum: 1
            maximum: 128
          prediction:
            nullable: true
            description: |
              Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
              which can greatly improve response times when large parts of the model
              response are known ahead of time. This is most common when you are
              regenerating a file with only minor changes to most of the content.
            x-oaiExpandable: true
            oneOf:
            - $ref: '#/components/schemas/PredictionContent'
          seed:
            nullable: true
            description: |
              This feature is in Beta.
              If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
              Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
            x-oaiMeta:
              beta: true
            type: integer
            format: int64
          stream_options:
            $ref: '#/components/schemas/ChatCompletionStreamOptions'
          tools:
            description: |
              A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionTool'
          tool_choice:
            $ref: '#/components/schemas/ChatCompletionToolChoiceOption'
          parallel_tool_calls:
            $ref: '#/components/schemas/ParallelToolCalls'
          function_call:
            deprecated: true
            description: |
              Deprecated in favor of `tool_choice`.

              Controls which (if any) function is called by the model.

              `none` means the model will not call a function and instead generates a
              message.

              `auto` means the model can pick between generating a message or calling a
              function.

              Specifying a particular function via `{"name": "my_function"}` forces the
              model to call that function.

              `none` is the default when no functions are present. `auto` is the default
              if functions are present.
            x-oaiExpandable: true
            oneOf:
            - description: |
                `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.
              type: string
              enum:
              - none
              - auto
            - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
          functions:
            deprecated: true
            description: |
              Deprecated in favor of `tools`.

              A list of functions the model may generate JSON inputs for.
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionFunctions'
            minItems: 1
            maxItems: 128
        required:
        - model
        - messages
    CreateChatCompletionResponse:
      description: Represents a chat completion response returned by model, based on the provided input.
      x-oaiMeta:
        example: |
          {
            "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
            "object": "chat.completion",
            "created": 1741570283,
            "model": "gpt-4o-2024-08-06",
            "choices": [
              {
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
                  "refusal": null,
                  "annotations": []
                },
                "logprobs": null,
                "finish_reason": "stop"
              }
            ],
            "usage": {
              "prompt_tokens": 1117,
              "completion_tokens": 46,
              "total_tokens": 1163,
              "prompt_tokens_details": {
                "cached_tokens": 0,
                "audio_tokens": 0
              },
              "completion_tokens_details": {
                "reasoning_tokens": 0,
                "audio_tokens": 0,
                "accepted_prediction_tokens": 0,
                "rejected_prediction_tokens": 0
              }
            },
            "service_tier": "default",
            "system_fingerprint": "fp_fc9f1d7035"
          }
        group: chat
        name: The chat completion object
      type: object
      properties:
        id:
          description: A unique identifier for the chat completion.
          type: string
        choices:
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
          type: array
          items:
            type: object
            properties:
              finish_reason:
                description: |
                  The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
                  `length` if the maximum number of tokens specified in the request was reached,
                  `content_filter` if content was omitted due to a flag from our content filters,
                  `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
                type: string
                enum:
                - stop
                - length
                - tool_calls
                - content_filter
                - function_call
              index:
                description: The index of the choice in the list of choices.
                type: integer
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
              logprobs:
                nullable: true
                description: Log probability information for the choice.
                type: object
                properties:
                  content:
                    nullable: true
                    description: A list of message content tokens with log probability information.
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                  refusal:
                    nullable: true
                    description: A list of message refusal tokens with log probability information.
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                required:
                - content
                - refusal
            required:
            - finish_reason
            - index
            - message
            - logprobs
        created:
          description: The Unix timestamp (in seconds) of when the chat completion was created.
          type: integer
        model:
          description: The model used for the chat completion.
          type: string
        service_tier:
          nullable: true
          example: scale
          description: The service tier used for processing the request.
          type: string
          enum:
          - scale
          - default
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: The object type, which is always `chat.completion`.
          x-stainless-const: true
          type: string
          enum:
          - chat.completion
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - choices
      - created
      - id
      - model
      - object
    CreateChatCompletionStreamResponse:
      description: "Represents a streamed chunk of a chat completion response returned\nby the model, based on the provided input. \n[Learn more](/docs/guides/streaming-responses).\n"
      x-oaiMeta:
        example: |
          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

          ....

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
        group: chat
        name: The chat completion chunk object
      type: object
      properties:
        id:
          description: A unique identifier for the chat completion. Each chunk has the same ID.
          type: string
        choices:
          description: |
            A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
            last chunk if you set `stream_options: {"include_usage": true}`.
          type: array
          items:
            type: object
            properties:
              delta:
                $ref: '#/components/schemas/ChatCompletionStreamResponseDelta'
              logprobs:
                nullable: true
                description: Log probability information for the choice.
                type: object
                properties:
                  content:
                    nullable: true
                    description: A list of message content tokens with log probability information.
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                  refusal:
                    nullable: true
                    description: A list of message refusal tokens with log probability information.
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                required:
                - content
                - refusal
              finish_reason:
                nullable: true
                description: |
                  The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
                  `length` if the maximum number of tokens specified in the request was reached,
                  `content_filter` if content was omitted due to a flag from our content filters,
                  `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
                type: string
                enum:
                - stop
                - length
                - tool_calls
                - content_filter
                - function_call
              index:
                description: The index of the choice in the list of choices.
                type: integer
            required:
            - delta
            - finish_reason
            - index
        created:
          description: The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
          type: integer
        model:
          description: The model to generate the completion.
          type: string
        service_tier:
          nullable: true
          example: scale
          description: The service tier used for processing the request.
          type: string
          enum:
          - scale
          - default
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.
            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: The object type, which is always `chat.completion.chunk`.
          x-stainless-const: true
          type: string
          enum:
          - chat.completion.chunk
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - choices
      - created
      - id
      - model
      - object
    CreateCompletionRequest:
      type: object
      properties:
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.
          x-oaiTypeLabel: string
          anyOf:
          - type: string
          - type: string
            enum:
            - gpt-3.5-turbo-instruct
            - davinci-002
            - babbage-002
        prompt:
          nullable: true
          description: |
            The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

            Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
          default: <|endoftext|>
          oneOf:
          - example: This is a test.
            default: ''
            type: string
          - type: array
            items:
              example: This is a test.
              default: ''
              type: string
          - example: '[1212, 318, 257, 1332, 13]'
            type: array
            items:
              type: integer
            minItems: 1
          - example: '[[1212, 318, 257, 1332, 13]]'
            type: array
            items:
              type: array
              items:
                type: integer
              minItems: 1
            minItems: 1
        best_of:
          nullable: true
          description: |
            Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          default: 1
          type: integer
          minimum: 0
          maximum: 20
        echo:
          nullable: true
          description: |
            Echo back the prompt in addition to the completion
          default: false
          type: boolean
        frequency_penalty:
          nullable: true
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation)
          default: 0
          type: number
          minimum: -2.0
          maximum: 2.0
        logit_bias:
          nullable: true
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
          x-oaiTypeLabel: map
          type: object
          additionalProperties:
            type: integer
        logprobs:
          nullable: true
          description: |
            Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

            The maximum value for `logprobs` is 5.
          type: integer
          minimum: 0
          maximum: 5
        max_tokens:
          nullable: true
          example: 16
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          default: 16
          type: integer
          minimum: 0
        n:
          nullable: true
          example: 1
          description: |
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          default: 1
          type: integer
          minimum: 1
          maximum: 128
        presence_penalty:
          nullable: true
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation)
          default: 0
          type: number
          minimum: -2.0
          maximum: 2.0
        seed:
          nullable: true
          description: |
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
          type: integer
          format: int64
        stop:
          $ref: '#/components/schemas/StopConfiguration'
        stream:
          nullable: true
          description: |
            Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          default: false
          type: boolean
        stream_options:
          $ref: '#/components/schemas/ChatCompletionStreamOptions'
        suffix:
          nullable: true
          example: test.
          description: |
            The suffix that comes after a completion of inserted text.

            This parameter is only supported for `gpt-3.5-turbo-instruct`.
          type: string
        temperature:
          nullable: true
          example: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          default: 1
          type: number
          minimum: 0.0
          maximum: 2.0
        top_p:
          nullable: true
          example: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          default: 1
          type: number
          minimum: 0.0
          maximum: 1.0
        user:
          example: user-1234
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).
          type: string
      required:
      - model
      - prompt
    CreateCompletionResponse:
      description: |
        Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).
      x-oaiMeta:
        example: |
          {
            "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
            "object": "text_completion",
            "created": 1589478378,
            "model": "gpt-4-turbo",
            "choices": [
              {
                "text": "\n\nThis is indeed a test",
                "index": 0,
                "logprobs": null,
                "finish_reason": "length"
              }
            ],
            "usage": {
              "prompt_tokens": 5,
              "completion_tokens": 7,
              "total_tokens": 12
            }
          }
        legacy: true
        name: The completion object
      type: object
      properties:
        id:
          description: A unique identifier for the completion.
          type: string
        choices:
          description: The list of completion choices the model generated for the input prompt.
          type: array
          items:
            type: object
            properties:
              finish_reason:
                description: |
                  The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
                  `length` if the maximum number of tokens specified in the request was reached,
                  or `content_filter` if content was omitted due to a flag from our content filters.
                type: string
                enum:
                - stop
                - length
                - content_filter
              index:
                type: integer
              logprobs:
                nullable: true
                type: object
                properties:
                  text_offset:
                    type: array
                    items:
                      type: integer
                  token_logprobs:
                    type: array
                    items:
                      type: number
                  tokens:
                    type: array
                    items:
                      type: string
                  top_logprobs:
                    type: array
                    items:
                      type: object
                      additionalProperties:
                        type: number
              text:
                type: string
            required:
            - finish_reason
            - index
            - logprobs
            - text
        created:
          description: The Unix timestamp (in seconds) of when the completion was created.
          type: integer
        model:
          description: The model used for completion.
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: The object type, which is always "text_completion"
          x-stainless-const: true
          type: string
          enum:
          - text_completion
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - id
      - object
      - created
      - model
      - choices
    CreateModelResponseProperties:
      allOf:
      - $ref: '#/components/schemas/ModelResponseProperties'
    CreateResponse:
      allOf:
      - $ref: '#/components/schemas/CreateModelResponseProperties'
      - $ref: '#/components/schemas/ResponseProperties'
      - type: object
        properties:
          input:
            description: |
              Text, image, or file inputs to the model, used to generate a response.

              Learn more:
              - [Text inputs and outputs](/docs/guides/text)
              - [Image inputs](/docs/guides/images)
              - [File inputs](/docs/guides/pdf-files)
              - [Conversation state](/docs/guides/conversation-state)
              - [Function calling](/docs/guides/function-calling)
            x-oaiExpandable: true
            oneOf:
            - title: Text input
              description: "A text input to the model, equivalent to a text input with the \n`user` role.\n"
              type: string
            - title: Input item list
              description: "A list of one or many input items to the model, containing \ndifferent content types.\n"
              type: array
              items:
                $ref: '#/components/schemas/InputItem'
          include:
            nullable: true
            description: |
              Specify additional output data to include in the model response. Currently
              supported values are:
              - `file_search_call.results`: Include the search results of
                the file search tool call.
              - `message.input_image.image_url`: Include image urls from the input message.
              - `computer_call_output.output.image_url`: Include image urls from the computer call output.
            type: array
            items:
              $ref: '#/components/schemas/Includable'
          parallel_tool_calls:
            nullable: true
            description: |
              Whether to allow the model to run tool calls in parallel.
            default: true
            type: boolean
          store:
            nullable: true
            description: |
              Whether to store the generated model response for later retrieval via
              API.
            default: true
            type: boolean
          stream:
            nullable: true
            description: |
              If set to true, the model response data will be streamed to the client
              as it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).
              See the [Streaming section below](/docs/api-reference/responses-streaming)
              for more information.
            default: false
            type: boolean
        required:
        - model
        - input
    DoubleClick:
      title: DoubleClick
      description: |
        A double click action.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a double click action, this property is \nalways set to `double_click`.\n"
          default: double_click
          x-stainless-const: true
          type: string
          enum:
          - double_click
        x:
          description: |
            The x-coordinate where the double click occurred.
          type: integer
        y:
          description: |
            The y-coordinate where the double click occurred.
          type: integer
      required:
      - type
      - x
      - y
    Drag:
      title: Drag
      description: |
        A drag action.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a drag action, this property is \nalways set to `drag`.\n"
          default: drag
          x-stainless-const: true
          type: string
          enum:
          - drag
        path:
          description: |
            An array of coordinates representing the path of the drag action. Coordinates will appear as an array
            of objects, eg
            ```
            [
              { x: 100, y: 200 },
              { x: 200, y: 300 }
            ]
            ```
          x-oaiExpandable: true
          type: array
          items:
            $ref: '#/components/schemas/Coordinate'
      required:
      - type
      - path
    EasyInputMessage:
      title: Input message
      description: |
        A message input to the model with a role indicating instruction following
        hierarchy. Instructions given with the `developer` or `system` role take
        precedence over instructions given with the `user` role. Messages with the
        `assistant` role are presumed to have been generated by the model in previous
        interactions.
      type: object
      properties:
        role:
          description: |
            The role of the message input. One of `user`, `assistant`, `system`, or
            `developer`.
          type: string
          enum:
          - user
          - assistant
          - system
          - developer
        content:
          description: |
            Text, image, or audio input to the model, used to generate a response.
            Can also contain previous assistant responses.
          x-oaiExpandable: true
          oneOf:
          - title: Text input
            description: |
              A text input to the model.
            type: string
          - $ref: '#/components/schemas/InputMessageContentList'
        type:
          description: |
            The type of the message input. Always `message`.
          x-stainless-const: true
          type: string
          enum:
          - message
      required:
      - role
      - content
    FileCitation:
      title: File citation
      description: |
        A citation to a file.
      type: object
      properties:
        type:
          description: |
            The type of the file citation. Always `file_citation`.
          x-stainless-const: true
          type: string
          enum:
          - file_citation
        index:
          description: |
            The index of the file in the list of files.
          type: integer
        file_id:
          description: |
            The ID of the file.
          type: string
      required:
      - type
      - index
      - file_id
    FilePath:
      title: File path
      description: |
        A path to a file.
      type: object
      properties:
        type:
          description: |
            The type of the file path. Always `file_path`.
          x-stainless-const: true
          type: string
          enum:
          - file_path
        file_id:
          description: |
            The ID of the file.
          type: string
        index:
          description: |
            The index of the file in the list of files.
          type: integer
      required:
      - type
      - file_id
      - index
    FileSearchTool:
      title: File search
      description: |
        A tool that searches for relevant content from uploaded files.
        Learn more about the [file search tool](/docs/guides/tools-file-search).
      type: object
      properties:
        type:
          description: |
            The type of the file search tool. Always `file_search`.
          x-stainless-const: true
          type: string
          enum:
          - file_search
        vector_store_ids:
          description: |
            The IDs of the vector stores to search.
          type: array
          items:
            type: string
        max_num_results:
          description: "The maximum number of results to return. This number should be between 1 \nand 50 inclusive.\n"
          type: integer
        filters:
          description: A filter to apply based on file attributes.
          x-oaiExpandable: true
          oneOf:
          - $ref: '#/components/schemas/ComparisonFilter'
          - $ref: '#/components/schemas/CompoundFilter'
        ranking_options:
          description: Ranking options for search.
          type: object
          properties:
            ranker:
              description: The ranker to use for the file search.
              default: auto
              type: string
              enum:
              - auto
              - default-2024-11-15
            score_threshold:
              description: |
                The score threshold for the file search, a number between 0 and 1.
                Numbers closer to 1 will attempt to return only the most relevant
                results, but may return fewer results.
              default: 0
              type: number
              minimum: 0.0
              maximum: 1.0
          additionalProperties: false
      required:
      - type
      - vector_store_ids
    FileSearchToolCall:
      title: File search tool call
      description: "The results of a file search tool call. See the \n[file search guide](/docs/guides/tools-file-search) for more information.\n"
      type: object
      properties:
        id:
          description: |
            The unique ID of the file search tool call.
          type: string
        type:
          description: |
            The type of the file search tool call. Always `file_search_call`.
          x-stainless-const: true
          type: string
          enum:
          - file_search_call
        status:
          description: "The status of the file search tool call. One of `in_progress`, \n`searching`, `incomplete` or `failed`,\n"
          type: string
          enum:
          - in_progress
          - searching
          - completed
          - incomplete
          - failed
        queries:
          description: |
            The queries used to search for files.
          type: array
          items:
            type: string
        results:
          nullable: true
          description: |
            The results of the file search tool call.
          type: array
          items:
            type: object
            properties:
              file_id:
                description: |
                  The unique ID of the file.
                type: string
              text:
                description: |
                  The text that was retrieved from the file.
                type: string
              filename:
                description: |
                  The name of the file.
                type: string
              attributes:
                $ref: '#/components/schemas/VectorStoreFileAttributes'
              score:
                description: |
                  The relevance score of the file - a value between 0 and 1.
                type: number
                format: float
      required:
      - id
      - type
      - status
      - queries
    FunctionObject:
      type: object
      properties:
        description:
          description: A description of what the function does, used by the model to choose when and how to call the function.
          type: string
        name:
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
          type: string
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
        strict:
          nullable: true
          description: Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](docs/guides/function-calling).
          default: false
          type: boolean
      required:
      - name
    FunctionParameters:
      description: "The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. \n\nOmitting `parameters` defines a function with an empty parameter list."
      type: object
      additionalProperties: true
    FunctionTool:
      title: Function
      description: |
        Defines a function in your own code the model can choose to call. Learn more
        about [function calling](/docs/guides/function-calling).
      type: object
      properties:
        type:
          description: |
            The type of the function tool. Always `function`.
          x-stainless-const: true
          type: string
          enum:
          - function
        name:
          description: |
            The name of the function to call.
          type: string
        description:
          nullable: true
          description: |
            A description of the function. Used by the model to determine whether
            or not to call the function.
          type: string
        parameters:
          description: |
            A JSON schema object describing the parameters of the function.
          type: object
          additionalProperties: true
        strict:
          description: |
            Whether to enforce strict parameter validation. Default `true`.
          type: boolean
      required:
      - type
      - name
      - parameters
      - strict
    FunctionToolCall:
      title: Function tool call
      description: "A tool call to run a function. See the \n[function calling guide](/docs/guides/function-calling) for more information.\n"
      type: object
      properties:
        id:
          description: |
            The unique ID of the function tool call.
          type: string
        type:
          description: |
            The type of the function tool call. Always `function_call`.
          x-stainless-const: true
          type: string
          enum:
          - function_call
        call_id:
          description: |
            The unique ID of the function tool call generated by the model.
          type: string
        name:
          description: |
            The name of the function to run.
          type: string
        arguments:
          description: |
            A JSON string of the arguments to pass to the function.
          type: string
        status:
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API.
          type: string
          enum:
          - in_progress
          - completed
          - incomplete
      required:
      - type
      - call_id
      - name
      - arguments
    Includable:
      description: |
        Specify additional output data to include in the model response. Currently
        supported values are:
        - `file_search_call.results`: Include the search results of
          the file search tool call.
        - `message.input_image.image_url`: Include image urls from the input message.
        - `computer_call_output.output.image_url`: Include image urls from the computer call output.
      type: string
      enum:
      - file_search_call.results
      - message.input_image.image_url
      - computer_call_output.output.image_url
    InputContent:
      x-oaiExpandable: true
      oneOf:
      - $ref: '#/components/schemas/InputText'
      - $ref: '#/components/schemas/InputImage'
      - $ref: '#/components/schemas/InputFile'
    InputFile:
      title: File input
      description: |
        A file input to the model.
      type: object
      properties:
        type:
          description: |
            The type of the input item. Always `input_file`.
          x-stainless-const: true
          type: string
          enum:
          - input_file
        file_id:
          description: |
            The ID of the file to be sent to the model.
          type: string
        filename:
          description: |
            The name of the file to be sent to the model.
          type: string
        file_data:
          description: |
            The content of the file to be sent to the model.
          type: string
      required:
      - type
    InputImage:
      title: Image input
      description: |
        An image input to the model. Learn about [image inputs](/docs/guides/vision).
      type: object
      properties:
        type:
          description: |
            The type of the input item. Always `input_image`.
          x-stainless-const: true
          type: string
          enum:
          - input_image
        image_url:
          nullable: true
          description: |
            The URL of the image to be sent to the model. A fully qualified URL or
            base64 encoded image in a data URL.
          type: string
        file_id:
          nullable: true
          description: |
            The ID of the file to be sent to the model.
          type: string
        detail:
          description: |
            The detail level of the image to be sent to the model. One of `high`,
            `low`, or `auto`. Defaults to `auto`.
          default: auto
          type: string
          enum:
          - high
          - low
          - auto
      required:
      - type
      - detail
    InputItem:
      discriminator:
        propertyName: type
      oneOf:
      - $ref: '#/components/schemas/EasyInputMessage'
      - $ref: '#/components/schemas/Item'
      - $ref: '#/components/schemas/ItemReference'
    InputMessageContentList:
      title: Input item content list
      description: "A list of one or many input items to the model, containing different content \ntypes.\n"
      x-oaiExpandable: true
      type: array
      items:
        $ref: '#/components/schemas/InputContent'
    InputText:
      title: Text input
      description: |
        A text input to the model.
      type: object
      properties:
        type:
          description: |
            The type of the input item. Always `input_text`.
          x-stainless-const: true
          type: string
          enum:
          - input_text
        text:
          description: |
            The text input to the model.
          type: string
      required:
      - type
      - text
    Item:
      description: |
        Content item used to generate a response.
      discriminator:
        propertyName: type
      x-oaiExpandable: true
      type: object
      oneOf:
      - $ref: '#/components/schemas/InputMessage'
      - $ref: '#/components/schemas/OutputMessage'
      - $ref: '#/components/schemas/FileSearchToolCall'
      - $ref: '#/components/schemas/ComputerToolCall'
      - $ref: '#/components/schemas/ComputerToolCallOutput'
      - $ref: '#/components/schemas/WebSearchToolCall'
      - $ref: '#/components/schemas/FunctionToolCall'
      - $ref: '#/components/schemas/FunctionToolCallOutput'
      - $ref: '#/components/schemas/ReasoningItem'
    ItemReference:
      title: Item reference
      description: |
        An internal identifier for an item to reference.
      type: object
      properties:
        id:
          description: |
            The ID of the item to reference.
          type: string
        type:
          description: |
            The type of item to reference. Always `item_reference`.
          x-stainless-const: true
          type: string
          enum:
          - item_reference
      required:
      - id
      - type
    KeyPress:
      title: KeyPress
      description: |
        A collection of keypresses the model would like to perform.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a keypress action, this property is \nalways set to `keypress`.\n"
          default: keypress
          x-stainless-const: true
          type: string
          enum:
          - keypress
        keys:
          description: |
            The combination of keys the model is requesting to be pressed. This is an
            array of strings, each representing a key.
          type: array
          items:
            description: |
              One of the keys the model is requesting to be pressed.
            type: string
      required:
      - type
      - keys
    Metadata:
      nullable: true
      description: "Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. \n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n"
      x-oaiTypeLabel: map
      type: object
      additionalProperties:
        type: string
    ModelIdsResponses:
      example: gpt-4o
      anyOf:
      - $ref: '#/components/schemas/ModelIdsShared'
      - type: string
        enum:
        - o1-pro
        - o1-pro-2025-03-19
        - computer-use-preview
        - computer-use-preview-2025-03-11
    ModelIdsShared:
      example: gpt-4o
      anyOf:
      - type: string
      - type: string
        enum:
        - o3-mini
        - o3-mini-2025-01-31
        - o1
        - o1-2024-12-17
        - o1-preview
        - o1-preview-2024-09-12
        - o1-mini
        - o1-mini-2024-09-12
        - gpt-4o
        - gpt-4o-2024-11-20
        - gpt-4o-2024-08-06
        - gpt-4o-2024-05-13
        - gpt-4o-audio-preview
        - gpt-4o-audio-preview-2024-10-01
        - gpt-4o-audio-preview-2024-12-17
        - gpt-4o-mini-audio-preview
        - gpt-4o-mini-audio-preview-2024-12-17
        - gpt-4o-search-preview
        - gpt-4o-mini-search-preview
        - gpt-4o-search-preview-2025-03-11
        - gpt-4o-mini-search-preview-2025-03-11
        - chatgpt-4o-latest
        - gpt-4o-mini
        - gpt-4o-mini-2024-07-18
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0301
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
    ModelResponseProperties:
      type: object
      properties:
        metadata:
          $ref: '#/components/schemas/Metadata'
        temperature:
          nullable: true
          example: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
            We generally recommend altering this or `top_p` but not both.
          default: 1
          type: number
          minimum: 0.0
          maximum: 2.0
        top_p:
          nullable: true
          example: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling,
            where the model considers the results of the tokens with top_p probability
            mass. So 0.1 means only the tokens comprising the top 10% probability mass
            are considered.

            We generally recommend altering this or `temperature` but not both.
          default: 1
          type: number
          minimum: 0.0
          maximum: 1.0
        user:
          example: user-1234
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).
          type: string
    Move:
      title: Move
      description: |
        A mouse move action.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a move action, this property is \nalways set to `move`.\n"
          default: move
          x-stainless-const: true
          type: string
          enum:
          - move
        x:
          description: |
            The x-coordinate to move to.
          type: integer
        y:
          description: |
            The y-coordinate to move to.
          type: integer
      required:
      - type
      - x
      - y
    OutputContent:
      oneOf:
      - $ref: '#/components/schemas/OutputText'
      - $ref: '#/components/schemas/Refusal'
    OutputItem:
      discriminator:
        propertyName: type
      x-oaiExpandable: true
      anyOf:
      - $ref: '#/components/schemas/OutputMessage'
      - $ref: '#/components/schemas/FileSearchToolCall'
      - $ref: '#/components/schemas/FunctionToolCall'
      - $ref: '#/components/schemas/WebSearchToolCall'
      - $ref: '#/components/schemas/ComputerToolCall'
      - $ref: '#/components/schemas/ReasoningItem'
    OutputMessage:
      title: Output message
      description: |
        An output message from the model.
      type: object
      properties:
        id:
          description: |
            The unique ID of the output message.
          type: string
        type:
          description: |
            The type of the output message. Always `message`.
          x-stainless-const: true
          type: string
          enum:
          - message
        role:
          description: |
            The role of the output message. Always `assistant`.
          x-stainless-const: true
          type: string
          enum:
          - assistant
        content:
          description: |
            The content of the output message.
          x-oaiExpandable: true
          type: array
          items:
            $ref: '#/components/schemas/OutputContent'
        status:
          description: |
            The status of the message input. One of `in_progress`, `completed`, or
            `incomplete`. Populated when input items are returned via API.
          type: string
          enum:
          - in_progress
          - completed
          - incomplete
      required:
      - id
      - type
      - role
      - content
      - status
    OutputText:
      title: Output text
      description: |
        A text output from the model.
      type: object
      properties:
        type:
          description: |
            The type of the output text. Always `output_text`.
          x-stainless-const: true
          type: string
          enum:
          - output_text
        text:
          description: |
            The text output from the model.
          type: string
        annotations:
          description: |
            The annotations of the text output.
          type: array
          items:
            $ref: '#/components/schemas/Annotation'
      required:
      - type
      - text
      - annotations
    ParallelToolCalls:
      description: Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.
      default: true
      type: boolean
    PredictionContent:
      title: Static Content
      description: |
        Static predicted output content, such as the content of a text file that is
        being regenerated.
      type: object
      properties:
        type:
          description: |
            The type of the predicted content you want to provide. This type is
            currently always `content`.
          x-stainless-const: true
          type: string
          enum:
          - content
        content:
          description: |
            The content that should be matched when generating a model response.
            If generated tokens would match this content, the entire model response
            can be returned much more quickly.
          x-oaiExpandable: true
          oneOf:
          - title: Text content
            description: |
              The content used for a Predicted Output. This is often the
              text of a file you are regenerating with minor changes.
            type: string
          - title: Array of content parts
            description: An array of content parts with a defined type. Supported options differ based on the [model](/docs/models) being used to generate the response. Can contain text inputs.
            type: array
            items:
              $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
            minItems: 1
      required:
      - type
      - content
    Reasoning:
      title: Reasoning
      description: "**o-series models only**\n\nConfiguration options for \n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\n"
      x-oaiExpandable: true
      type: object
      properties:
        effort:
          $ref: '#/components/schemas/ReasoningEffort'
        generate_summary:
          nullable: true
          description: |
            **computer_use_preview only**

            A summary of the reasoning performed by the model. This can be
            useful for debugging and understanding the model's reasoning process.
            One of `concise` or `detailed`.
          type: string
          enum:
          - concise
          - detailed
    ReasoningEffort:
      nullable: true
      description: "**o-series models only** \n\nConstrains effort on reasoning for \n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n"
      default: medium
      type: string
      enum:
      - low
      - medium
      - high
    ReasoningItem:
      title: Reasoning
      description: |
        A description of the chain of thought used by a reasoning model while generating
        a response.
      x-oaiExpandable: true
      type: object
      properties:
        type:
          description: |
            The type of the object. Always `reasoning`.
          x-stainless-const: true
          type: string
          enum:
          - reasoning
        id:
          description: |
            The unique identifier of the reasoning content.
          type: string
        summary:
          description: |
            Reasoning text contents.
          type: array
          items:
            type: object
            properties:
              type:
                description: |
                  The type of the object. Always `summary_text`.
                x-stainless-const: true
                type: string
                enum:
                - summary_text
              text:
                description: |
                  A short summary of the reasoning used by the model when generating
                  the response.
                type: string
            required:
            - type
            - text
        status:
          description: |
            The status of the item. One of `in_progress`, `completed`, or
            `incomplete`. Populated when items are returned via API.
          type: string
          enum:
          - in_progress
          - completed
          - incomplete
      required:
      - id
      - summary
      - type
    Refusal:
      title: Refusal
      description: |
        A refusal from the model.
      type: object
      properties:
        type:
          description: |
            The type of the refusal. Always `refusal`.
          x-stainless-const: true
          type: string
          enum:
          - refusal
        refusal:
          description: |
            The refusal explanationfrom the model.
          type: string
      required:
      - type
      - refusal
    Response:
      allOf:
      - $ref: '#/components/schemas/ModelResponseProperties'
      - $ref: '#/components/schemas/ResponseProperties'
      - x-oaiMeta:
          example: |
            {
              "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
              "object": "response",
              "created_at": 1741476777,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [
                {
                  "type": "message",
                  "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
                  "status": "completed",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "generate_summary": null
              },
              "store": true,
              "temperature": 1.0,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1.0,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 328,
                "input_tokens_details": {
                  "cached_tokens": 0
                },
                "output_tokens": 52,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 380
              },
              "user": null,
              "metadata": {}
            }
          group: responses
          name: The response object
        type: object
        properties:
          id:
            description: |
              Unique identifier for this Response.
            type: string
          object:
            description: |
              The object type of this resource - always set to `response`.
            x-stainless-const: true
            type: string
            enum:
            - response
          status:
            description: "The status of the response generation. One of `completed`, `failed`, \n`in_progress`, or `incomplete`.\n"
            type: string
            enum:
            - completed
            - failed
            - in_progress
            - incomplete
          created_at:
            description: |
              Unix timestamp (in seconds) of when this Response was created.
            type: number
          error:
            $ref: '#/components/schemas/ResponseError'
          incomplete_details:
            nullable: true
            description: |
              Details about why the response is incomplete.
            type: object
            properties:
              reason:
                description: The reason why the response is incomplete.
                type: string
                enum:
                - max_output_tokens
                - content_filter
          output:
            description: "An array of content items generated by the model.\n\n- The length and order of items in the `output` array is dependent\n  on the model's response.\n- Rather than accessing the first item in the `output` array and \n  assuming it's an `assistant` message with the content generated by\n  the model, you might consider using the `output_text` property where\n  supported in SDKs.\n"
            x-oaiExpandable: true
            type: array
            items:
              $ref: '#/components/schemas/OutputItem'
          output_text:
            nullable: true
            description: "SDK-only convenience property that contains the aggregated text output \nfrom all `output_text` items in the `output` array, if any are present. \nSupported in the Python and JavaScript SDKs.\n"
            x-oaiSupportedSDKs:
            - python
            - javascript
            type: string
          usage:
            $ref: '#/components/schemas/ResponseUsage'
          parallel_tool_calls:
            description: |
              Whether to allow the model to run tool calls in parallel.
            default: true
            type: boolean
        required:
        - id
        - object
        - created_at
        - error
        - incomplete_details
        - instructions
        - model
        - tools
        - output
        - parallel_tool_calls
        - metadata
        - tool_choice
        - temperature
        - top_p
    ResponseAudioDeltaEvent:
      description: Emitted when there is a partial audio response.
      x-oaiMeta:
        example: |
          {
            "type": "response.audio.delta",
            "response_id": "resp_123",
            "delta": "base64encoded..."
          }
        group: responses
        name: response.audio.delta
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.audio.delta`.
          x-stainless-const: true
          type: string
          enum:
          - response.audio.delta
        delta:
          description: |
            A chunk of Base64 encoded response audio bytes.
          type: string
      required:
      - type
      - delta
    ResponseAudioDoneEvent:
      description: Emitted when the audio response is complete.
      x-oaiMeta:
        example: |
          {
            "type": "response.audio.done",
            "response_id": "resp-123"
          }
        group: responses
        name: response.audio.done
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.audio.done`.
          x-stainless-const: true
          type: string
          enum:
          - response.audio.done
      required:
      - type
      - response_id
    ResponseAudioTranscriptDeltaEvent:
      description: Emitted when there is a partial transcript of audio.
      x-oaiMeta:
        example: |
          {
            "type": "response.audio.transcript.delta",
            "response_id": "resp_123",
            "delta": " ... partial transcript ... "
          }
        group: responses
        name: response.audio.transcript.delta
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.audio.transcript.delta`.
          x-stainless-const: true
          type: string
          enum:
          - response.audio.transcript.delta
        delta:
          description: |
            The partial transcript of the audio response.
          type: string
      required:
      - type
      - response_id
      - delta
    ResponseAudioTranscriptDoneEvent:
      description: Emitted when the full audio transcript is completed.
      x-oaiMeta:
        example: |
          {
            "type": "response.audio.transcript.done",
            "response_id": "resp_123"
          }
        group: responses
        name: response.audio.transcript.done
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.audio.transcript.done`.
          x-stainless-const: true
          type: string
          enum:
          - response.audio.transcript.done
      required:
      - type
      - response_id
    ResponseCodeInterpreterCallCodeDeltaEvent:
      description: Emitted when a partial code snippet is added by the code interpreter.
      x-oaiMeta:
        example: |
          {
            "type": "response.code_interpreter_call.code.delta",
            "response_id": "resp-123",
            "output_index": 0,
            "delta": "partial code"
          }
        group: responses
        name: response.code_interpreter_call.code.delta
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.code_interpreter_call.code.delta`.
          x-stainless-const: true
          type: string
          enum:
          - response.code_interpreter_call.code.delta
        output_index:
          description: |
            The index of the output item that the code interpreter call is in progress.
          type: integer
        delta:
          description: |
            The partial code snippet added by the code interpreter.
          type: string
      required:
      - type
      - response_id
      - output_index
      - delta
    ResponseCodeInterpreterCallCodeDoneEvent:
      description: Emitted when code snippet output is finalized by the code interpreter.
      x-oaiMeta:
        example: |
          {
            "type": "response.code_interpreter_call.code.done",
            "response_id": "resp-123",
            "output_index": 3,
            "code": "console.log('done');"
          }
        group: responses
        name: response.code_interpreter_call.code.done
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.code_interpreter_call.code.done`.
          x-stainless-const: true
          type: string
          enum:
          - response.code_interpreter_call.code.done
        output_index:
          description: |
            The index of the output item that the code interpreter call is in progress.
          type: integer
        code:
          description: |
            The final code snippet output by the code interpreter.
          type: string
      required:
      - type
      - response_id
      - output_index
      - code
    ResponseCodeInterpreterCallCompletedEvent:
      description: Emitted when the code interpreter call is completed.
      x-oaiMeta:
        example: |
          {
            "type": "response.code_interpreter_call.completed",
            "response_id": "resp-123",
            "output_index": 5,
            "code_interpreter_call": {}
          }
        group: responses
        name: response.code_interpreter_call.completed
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.code_interpreter_call.completed`.
          x-stainless-const: true
          type: string
          enum:
          - response.code_interpreter_call.completed
        output_index:
          description: |
            The index of the output item that the code interpreter call is in progress.
          type: integer
        code_interpreter_call:
          $ref: '#/components/schemas/CodeInterpreterToolCall'
      required:
      - type
      - response_id
      - output_index
      - code_interpreter_call
    ResponseCodeInterpreterCallInProgressEvent:
      description: Emitted when a code interpreter call is in progress.
      x-oaiMeta:
        example: |
          {
            "type": "response.code_interpreter_call.in.progress",
            "response_id": "resp-123",
            "output_index": 0,
            "code_interpreter_call": {}
          }
        group: responses
        name: response.code_interpreter_call.in_progress
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.code_interpreter_call.in_progress`.
          x-stainless-const: true
          type: string
          enum:
          - response.code_interpreter_call.in_progress
        output_index:
          description: |
            The index of the output item that the code interpreter call is in progress.
          type: integer
        code_interpreter_call:
          $ref: '#/components/schemas/CodeInterpreterToolCall'
      required:
      - type
      - response_id
      - output_index
      - code_interpreter_call
    ResponseCodeInterpreterCallInterpretingEvent:
      description: Emitted when the code interpreter is actively interpreting the code snippet.
      x-oaiMeta:
        example: |
          {
            "type": "response.code_interpreter_call.interpreting",
            "response_id": "resp-123",
            "output_index": 4,
            "code_interpreter_call": {}
          }
        group: responses
        name: response.code_interpreter_call.interpreting
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.code_interpreter_call.interpreting`.
          x-stainless-const: true
          type: string
          enum:
          - response.code_interpreter_call.interpreting
        output_index:
          description: |
            The index of the output item that the code interpreter call is in progress.
          type: integer
        code_interpreter_call:
          $ref: '#/components/schemas/CodeInterpreterToolCall'
      required:
      - type
      - response_id
      - output_index
      - code_interpreter_call
    ResponseCompletedEvent:
      description: Emitted when the model response is complete.
      x-oaiMeta:
        example: |
          {
            "type": "response.completed",
            "response": {
              "id": "resp_123",
              "object": "response",
              "created_at": 1740855869,
              "status": "completed",
              "error": null,
              "incomplete_details": null,
              "input": [],
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-mini-2024-07-18",
              "output": [
                {
                  "id": "msg_123",
                  "type": "message",
                  "role": "assistant",
                  "content": [
                    {
                      "type": "output_text",
                      "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
                      "annotations": []
                    }
                  ]
                }
              ],
              "previous_response_id": null,
              "reasoning_effort": null,
              "store": false,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": {
                "input_tokens": 0,
                "output_tokens": 0,
                "output_tokens_details": {
                  "reasoning_tokens": 0
                },
                "total_tokens": 0
              },
              "user": null,
              "metadata": {}
            }
          }
        group: responses
        name: response.completed
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.completed`.
          x-stainless-const: true
          type: string
          enum:
          - response.completed
        response:
          $ref: '#/components/schemas/Response'
      required:
      - type
      - response
    ResponseContentPartAddedEvent:
      description: Emitted when a new content part is added.
      x-oaiMeta:
        example: |
          {
            "type": "response.content_part.added",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "part": {
              "type": "output_text",
              "text": "",
              "annotations": []
            }
          }
        group: responses
        name: response.content_part.added
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.content_part.added`.
          x-stainless-const: true
          type: string
          enum:
          - response.content_part.added
        item_id:
          description: |
            The ID of the output item that the content part was added to.
          type: string
        output_index:
          description: |
            The index of the output item that the content part was added to.
          type: integer
        content_index:
          description: |
            The index of the content part that was added.
          type: integer
        part:
          $ref: '#/components/schemas/OutputContent'
      required:
      - type
      - item_id
      - output_index
      - content_index
      - part
    ResponseContentPartDoneEvent:
      description: Emitted when a content part is done.
      x-oaiMeta:
        example: |
          {
            "type": "response.content_part.done",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "part": {
              "type": "output_text",
              "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
              "annotations": []
            }
          }
        group: responses
        name: response.content_part.done
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.content_part.done`.
          x-stainless-const: true
          type: string
          enum:
          - response.content_part.done
        item_id:
          description: |
            The ID of the output item that the content part was added to.
          type: string
        output_index:
          description: |
            The index of the output item that the content part was added to.
          type: integer
        content_index:
          description: |
            The index of the content part that is done.
          type: integer
        part:
          $ref: '#/components/schemas/OutputContent'
      required:
      - type
      - item_id
      - output_index
      - content_index
      - part
    ResponseCreatedEvent:
      description: |
        An event that is emitted when a response is created.
      x-oaiMeta:
        example: |
          {
            "type": "response.created",
            "response": {
              "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
              "object": "response",
              "created_at": 1741487325,
              "status": "in_progress",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "generate_summary": null
              },
              "store": true,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            }
          }
        group: responses
        name: response.created
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.created`.
          x-stainless-const: true
          type: string
          enum:
          - response.created
        response:
          $ref: '#/components/schemas/Response'
      required:
      - type
      - response
    ResponseError:
      nullable: true
      description: |
        An error object returned when the model fails to generate a Response.
      type: object
      properties:
        code:
          $ref: '#/components/schemas/ResponseErrorCode'
        message:
          description: |
            A human-readable description of the error.
          type: string
      required:
      - code
      - message
    ResponseErrorCode:
      description: |
        The error code for the response.
      type: string
      enum:
      - server_error
      - rate_limit_exceeded
      - invalid_prompt
      - vector_store_timeout
      - invalid_image
      - invalid_image_format
      - invalid_base64_image
      - invalid_image_url
      - image_too_large
      - image_too_small
      - image_parse_error
      - image_content_policy_violation
      - invalid_image_mode
      - image_file_too_large
      - unsupported_image_media_type
      - empty_image_file
      - failed_to_download_image
      - image_file_not_found
    ResponseErrorEvent:
      description: Emitted when an error occurs.
      x-oaiMeta:
        example: |
          {
            "type": "error",
            "code": "ERR_SOMETHING",
            "message": "Something went wrong",
            "param": null
          }
        group: responses
        name: error
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `error`.
          x-stainless-const: true
          type: string
          enum:
          - error
        code:
          nullable: true
          description: |
            The error code.
          type: string
        message:
          description: |
            The error message.
          type: string
        param:
          nullable: true
          description: |
            The error parameter.
          type: string
      required:
      - type
      - code
      - message
      - param
    ResponseFailedEvent:
      description: |
        An event that is emitted when a response fails.
      x-oaiMeta:
        example: |
          {
            "type": "response.failed",
            "response": {
              "id": "resp_123",
              "object": "response",
              "created_at": 1740855869,
              "status": "failed",
              "error": {
                "code": "server_error",
                "message": "The model failed to generate a response."
              },
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-mini-2024-07-18",
              "output": [],
              "previous_response_id": null,
              "reasoning_effort": null,
              "store": false,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            }
          }
        group: responses
        name: response.failed
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.failed`.
          x-stainless-const: true
          type: string
          enum:
          - response.failed
        response:
          $ref: '#/components/schemas/Response'
      required:
      - type
      - response
    ResponseFileSearchCallCompletedEvent:
      description: Emitted when a file search call is completed (results found).
      x-oaiMeta:
        example: |
          {
            "type": "response.file_search_call.completed",
            "output_index": 0,
            "item_id": "fs_123",
          }
        group: responses
        name: response.file_search_call.completed
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.file_search_call.completed`.
          x-stainless-const: true
          type: string
          enum:
          - response.file_search_call.completed
        output_index:
          description: |
            The index of the output item that the file search call is initiated.
          type: integer
        item_id:
          description: |
            The ID of the output item that the file search call is initiated.
          type: string
      required:
      - type
      - output_index
      - item_id
    ResponseFileSearchCallInProgressEvent:
      description: Emitted when a file search call is initiated.
      x-oaiMeta:
        example: |
          {
            "type": "response.file_search_call.in_progress",
            "output_index": 0,
            "item_id": "fs_123",
          }
        group: responses
        name: response.file_search_call.in_progress
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.file_search_call.in_progress`.
          x-stainless-const: true
          type: string
          enum:
          - response.file_search_call.in_progress
        output_index:
          description: |
            The index of the output item that the file search call is initiated.
          type: integer
        item_id:
          description: |
            The ID of the output item that the file search call is initiated.
          type: string
      required:
      - type
      - output_index
      - item_id
    ResponseFileSearchCallSearchingEvent:
      description: Emitted when a file search is currently searching.
      x-oaiMeta:
        example: |
          {
            "type": "response.file_search_call.searching",
            "output_index": 0,
            "item_id": "fs_123",
          }
        group: responses
        name: response.file_search_call.searching
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.file_search_call.searching`.
          x-stainless-const: true
          type: string
          enum:
          - response.file_search_call.searching
        output_index:
          description: |
            The index of the output item that the file search call is searching.
          type: integer
        item_id:
          description: |
            The ID of the output item that the file search call is initiated.
          type: string
      required:
      - type
      - output_index
      - item_id
    ResponseFormatJsonObject:
      title: JSON object
      description: |
        JSON object response format. An older method of generating JSON responses.
        Using `json_schema` is recommended for models that support it. Note that the
        model will not generate JSON without a system or user message instructing it
        to do so.
      type: object
      properties:
        type:
          description: The type of response format being defined. Always `json_object`.
          x-stainless-const: true
          type: string
          enum:
          - json_object
      required:
      - type
    ResponseFormatJsonSchema:
      title: JSON schema
      description: |
        JSON Schema response format. Used to generate structured JSON responses.
        Learn more about [Structured Outputs](/docs/guides/structured-outputs).
      type: object
      properties:
        type:
          description: The type of response format being defined. Always `json_schema`.
          x-stainless-const: true
          type: string
          enum:
          - json_schema
        json_schema:
          title: JSON schema
          description: |
            Structured Outputs configuration options, including a JSON Schema.
          type: object
          properties:
            description:
              description: |
                A description of what the response format is for, used by the model to
                determine how to respond in the format.
              type: string
            name:
              description: |
                The name of the response format. Must be a-z, A-Z, 0-9, or contain
                underscores and dashes, with a maximum length of 64.
              type: string
            schema:
              $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
            strict:
              nullable: true
              description: |
                Whether to enable strict schema adherence when generating the output.
                If set to true, the model will always follow the exact schema defined
                in the `schema` field. Only a subset of JSON Schema is supported when
                `strict` is `true`. To learn more, read the [Structured Outputs
                guide](/docs/guides/structured-outputs).
              default: false
              type: boolean
          required:
          - name
      required:
      - type
      - json_schema
    ResponseFormatJsonSchemaSchema:
      title: JSON schema
      description: |
        The schema for the response format, described as a JSON Schema object.
        Learn how to build JSON schemas [here](https://json-schema.org/).
      type: object
      additionalProperties: true
    ResponseFormatText:
      title: Text
      description: |
        Default response format. Used to generate text responses.
      type: object
      properties:
        type:
          description: The type of response format being defined. Always `text`.
          x-stainless-const: true
          type: string
          enum:
          - text
      required:
      - type
    ResponseFunctionCallArgumentsDeltaEvent:
      description: Emitted when there is a partial function-call arguments delta.
      x-oaiMeta:
        example: |
          {
            "type": "response.function_call_arguments.delta",
            "item_id": "item-abc",
            "output_index": 0,
            "delta": "{ \"arg\":"
          }
        group: responses
        name: response.function_call_arguments.delta
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.function_call_arguments.delta`.
          x-stainless-const: true
          type: string
          enum:
          - response.function_call_arguments.delta
        item_id:
          description: |
            The ID of the output item that the function-call arguments delta is added to.
          type: string
        output_index:
          description: |
            The index of the output item that the function-call arguments delta is added to.
          type: integer
        delta:
          description: |
            The function-call arguments delta that is added.
          type: string
      required:
      - type
      - item_id
      - output_index
      - delta
    ResponseFunctionCallArgumentsDoneEvent:
      description: Emitted when function-call arguments are finalized.
      x-oaiMeta:
        example: |
          {
            "type": "response.function_call_arguments.done",
            "item_id": "item-abc",
            "output_index": 1,
            "arguments": "{ \"arg\": 123 }"
          }
        group: responses
        name: response.function_call_arguments.done
      type: object
      properties:
        type:
          x-stainless-const: true
          type: string
          enum:
          - response.function_call_arguments.done
        item_id:
          description: The ID of the item.
          type: string
        output_index:
          description: The index of the output item.
          type: integer
        arguments:
          description: The function-call arguments.
          type: string
      required:
      - type
      - item_id
      - output_index
      - arguments
    ResponseInProgressEvent:
      description: Emitted when the response is in progress.
      x-oaiMeta:
        example: |
          {
            "type": "response.in_progress",
            "response": {
              "id": "resp_67ccfcdd16748190a91872c75d38539e09e4d4aac714747c",
              "object": "response",
              "created_at": 1741487325,
              "status": "in_progress",
              "error": null,
              "incomplete_details": null,
              "instructions": null,
              "max_output_tokens": null,
              "model": "gpt-4o-2024-08-06",
              "output": [],
              "parallel_tool_calls": true,
              "previous_response_id": null,
              "reasoning": {
                "effort": null,
                "generate_summary": null
              },
              "store": true,
              "temperature": 1,
              "text": {
                "format": {
                  "type": "text"
                }
              },
              "tool_choice": "auto",
              "tools": [],
              "top_p": 1,
              "truncation": "disabled",
              "usage": null,
              "user": null,
              "metadata": {}
            }
          }
        group: responses
        name: response.in_progress
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.in_progress`.
          x-stainless-const: true
          type: string
          enum:
          - response.in_progress
        response:
          $ref: '#/components/schemas/Response'
      required:
      - type
      - response
    ResponseIncompleteEvent:
      description: |
        An event that is emitted when a response finishes as incomplete.
      x-oaiMeta:
        example: "{\n  \"type\": \"response.incomplete\",\n  \"response\": {\n    \"id\": \"resp_123\",\n    \"object\": \"response\",\n    \"created_at\": 1740855869,\n    \"status\": \"incomplete\",\n    \"error\": null, \n    \"incomplete_details\": {\n      \"reason\": \"max_tokens\"\n    },\n    \"instructions\": null,\n    \"max_output_tokens\": null,\n    \"model\": \"gpt-4o-mini-2024-07-18\",\n    \"output\": [],\n    \"previous_response_id\": null,\n    \"reasoning_effort\": null,\n    \"store\": false,\n    \"temperature\": 1,\n    \"text\": {\n      \"format\": {\n        \"type\": \"text\"\n      }\n    },\n    \"tool_choice\": \"auto\",\n    \"tools\": [],\n    \"top_p\": 1,\n    \"truncation\": \"disabled\",\n    \"usage\": null,\n    \"user\": null,\n    \"metadata\": {}\n  }\n}\n"
        group: responses
        name: response.incomplete
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.incomplete`.
          x-stainless-const: true
          type: string
          enum:
          - response.incomplete
        response:
          $ref: '#/components/schemas/Response'
      required:
      - type
      - response
    ResponseModalities:
      nullable: true
      description: "Output types that you would like the model to generate.\nMost models are capable of generating text, which is the default:\n\n`[\"text\"]`\n\nThe `gpt-4o-audio-preview` model can also be used to \n[generate audio](/docs/guides/audio). To request that this model generate \nboth text and audio responses, you can use:\n\n`[\"text\", \"audio\"]`\n"
      type: array
      items:
        type: string
        enum:
        - text
        - audio
    ResponseOutputItemAddedEvent:
      description: Emitted when a new output item is added.
      x-oaiMeta:
        example: |
          {
            "type": "response.output_item.added",
            "output_index": 0,
            "item": {
              "id": "msg_123",
              "status": "in_progress",
              "type": "message",
              "role": "assistant",
              "content": []
            }
          }
        group: responses
        name: response.output_item.added
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.output_item.added`.
          x-stainless-const: true
          type: string
          enum:
          - response.output_item.added
        output_index:
          description: |
            The index of the output item that was added.
          type: integer
        item:
          $ref: '#/components/schemas/OutputItem'
      required:
      - type
      - output_index
      - item
    ResponseOutputItemDoneEvent:
      description: Emitted when an output item is marked done.
      x-oaiMeta:
        example: |
          {
            "type": "response.output_item.done",
            "output_index": 0,
            "item": {
              "id": "msg_123",
              "status": "completed",
              "type": "message",
              "role": "assistant",
              "content": [
                {
                  "type": "output_text",
                  "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic.",
                  "annotations": []
                }
              ]
            }
          }
        group: responses
        name: response.output_item.done
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.output_item.done`.
          x-stainless-const: true
          type: string
          enum:
          - response.output_item.done
        output_index:
          description: |
            The index of the output item that was marked done.
          type: integer
        item:
          $ref: '#/components/schemas/OutputItem'
      required:
      - type
      - output_index
      - item
    ResponseProperties:
      type: object
      properties:
        previous_response_id:
          nullable: true
          description: "The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about \n[conversation state](/docs/guides/conversation-state).\n"
          type: string
        model:
          $ref: '#/components/schemas/ModelIdsResponses'
        reasoning:
          $ref: '#/components/schemas/Reasoning'
        max_output_tokens:
          nullable: true
          description: |
            An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).
          type: integer
        instructions:
          nullable: true
          description: |
            Inserts a system (or developer) message as the first item in the model's context.

            When using along with `previous_response_id`, the instructions from a previous
            response will be not be carried over to the next response. This makes it simple
            to swap out system (or developer) messages in new responses.
          type: string
        text:
          description: |
            Configuration options for a text response from the model. Can be plain
            text or structured JSON data. Learn more:
            - [Text inputs and outputs](/docs/guides/text)
            - [Structured Outputs](/docs/guides/structured-outputs)
          type: object
          properties:
            format:
              $ref: '#/components/schemas/TextResponseFormatConfiguration'
        tools:
          description: "An array of tools the model may call while generating a response. You \ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model's capabilities, like [web search](/docs/guides/tools-web-search)\n  or [file search](/docs/guides/tools-file-search). Learn more about\n  [built-in tools](/docs/guides/tools).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code. Learn more about\n  [function calling](/docs/guides/function-calling).\n"
          type: array
          items:
            $ref: '#/components/schemas/Tool'
        tool_choice:
          description: |
            How the model should select which tool (or tools) to use when generating
            a response. See the `tools` parameter to see how to specify which tools
            the model can call.
          x-oaiExpandable: true
          oneOf:
          - $ref: '#/components/schemas/ToolChoiceOptions'
          - $ref: '#/components/schemas/ToolChoiceTypes'
          - $ref: '#/components/schemas/ToolChoiceFunction'
        truncation:
          nullable: true
          description: "The truncation strategy to use for the model response.\n- `auto`: If the context of this response and previous ones exceeds\n  the model's context window size, the model will truncate the \n  response to fit the context window by dropping input items in the\n  middle of the conversation. \n- `disabled` (default): If a model response will exceed the context window \n  size for a model, the request will fail with a 400 error.\n"
          default: disabled
          type: string
          enum:
          - auto
          - disabled
    ResponseRefusalDeltaEvent:
      description: Emitted when there is a partial refusal text.
      x-oaiMeta:
        example: |
          {
            "type": "response.refusal.delta",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "delta": "refusal text so far"
          }
        group: responses
        name: response.refusal.delta
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.refusal.delta`.
          x-stainless-const: true
          type: string
          enum:
          - response.refusal.delta
        item_id:
          description: |
            The ID of the output item that the refusal text is added to.
          type: string
        output_index:
          description: |
            The index of the output item that the refusal text is added to.
          type: integer
        content_index:
          description: |
            The index of the content part that the refusal text is added to.
          type: integer
        delta:
          description: |
            The refusal text that is added.
          type: string
      required:
      - type
      - item_id
      - output_index
      - content_index
      - delta
    ResponseRefusalDoneEvent:
      description: Emitted when refusal text is finalized.
      x-oaiMeta:
        example: |
          {
            "type": "response.refusal.done",
            "item_id": "item-abc",
            "output_index": 1,
            "content_index": 2,
            "refusal": "final refusal text"
          }
        group: responses
        name: response.refusal.done
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.refusal.done`.
          x-stainless-const: true
          type: string
          enum:
          - response.refusal.done
        item_id:
          description: |
            The ID of the output item that the refusal text is finalized.
          type: string
        output_index:
          description: |
            The index of the output item that the refusal text is finalized.
          type: integer
        content_index:
          description: |
            The index of the content part that the refusal text is finalized.
          type: integer
        refusal:
          description: |
            The refusal text that is finalized.
          type: string
      required:
      - type
      - item_id
      - output_index
      - content_index
      - refusal
    ResponseStreamEvent:
      discriminator:
        propertyName: type
      anyOf:
      - $ref: '#/components/schemas/ResponseAudioDeltaEvent'
      - $ref: '#/components/schemas/ResponseAudioDoneEvent'
      - $ref: '#/components/schemas/ResponseAudioTranscriptDeltaEvent'
      - $ref: '#/components/schemas/ResponseAudioTranscriptDoneEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCodeDeltaEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCodeDoneEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseCodeInterpreterCallInterpretingEvent'
      - $ref: '#/components/schemas/ResponseCompletedEvent'
      - $ref: '#/components/schemas/ResponseContentPartAddedEvent'
      - $ref: '#/components/schemas/ResponseContentPartDoneEvent'
      - $ref: '#/components/schemas/ResponseCreatedEvent'
      - $ref: '#/components/schemas/ResponseErrorEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseFileSearchCallSearchingEvent'
      - $ref: '#/components/schemas/ResponseFunctionCallArgumentsDeltaEvent'
      - $ref: '#/components/schemas/ResponseFunctionCallArgumentsDoneEvent'
      - $ref: '#/components/schemas/ResponseInProgressEvent'
      - $ref: '#/components/schemas/ResponseFailedEvent'
      - $ref: '#/components/schemas/ResponseIncompleteEvent'
      - $ref: '#/components/schemas/ResponseOutputItemAddedEvent'
      - $ref: '#/components/schemas/ResponseOutputItemDoneEvent'
      - $ref: '#/components/schemas/ResponseRefusalDeltaEvent'
      - $ref: '#/components/schemas/ResponseRefusalDoneEvent'
      - $ref: '#/components/schemas/ResponseTextAnnotationDeltaEvent'
      - $ref: '#/components/schemas/ResponseTextDeltaEvent'
      - $ref: '#/components/schemas/ResponseTextDoneEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallCompletedEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallInProgressEvent'
      - $ref: '#/components/schemas/ResponseWebSearchCallSearchingEvent'
    ResponseTextAnnotationDeltaEvent:
      description: Emitted when a text annotation is added.
      x-oaiMeta:
        example: |
          {
            "type": "response.output_text.annotation.added",
            "item_id": "msg_abc123",
            "output_index": 1,
            "content_index": 0,
            "annotation_index": 0,
            "annotation": {
              "type": "file_citation",
              "index": 390,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            }
          }
        group: responses
        name: response.output_text.annotation.added
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.output_text.annotation.added`.
          x-stainless-const: true
          type: string
          enum:
          - response.output_text.annotation.added
        item_id:
          description: |
            The ID of the output item that the text annotation was added to.
          type: string
        output_index:
          description: |
            The index of the output item that the text annotation was added to.
          type: integer
        content_index:
          description: |
            The index of the content part that the text annotation was added to.
          type: integer
        annotation_index:
          description: |
            The index of the annotation that was added.
          type: integer
        annotation:
          $ref: '#/components/schemas/Annotation'
      required:
      - type
      - item_id
      - output_index
      - content_index
      - annotation_index
      - annotation
    ResponseTextDeltaEvent:
      description: Emitted when there is an additional text delta.
      x-oaiMeta:
        example: |
          {
            "type": "response.output_text.delta",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "delta": "In"
          }
        group: responses
        name: response.output_text.delta
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.output_text.delta`.
          x-stainless-const: true
          type: string
          enum:
          - response.output_text.delta
        item_id:
          description: |
            The ID of the output item that the text delta was added to.
          type: string
        output_index:
          description: |
            The index of the output item that the text delta was added to.
          type: integer
        content_index:
          description: |
            The index of the content part that the text delta was added to.
          type: integer
        delta:
          description: |
            The text delta that was added.
          type: string
      required:
      - type
      - item_id
      - output_index
      - content_index
      - delta
    ResponseTextDoneEvent:
      description: Emitted when text content is finalized.
      x-oaiMeta:
        example: |
          {
            "type": "response.output_text.done",
            "item_id": "msg_123",
            "output_index": 0,
            "content_index": 0,
            "text": "In a shimmering forest under a sky full of stars, a lonely unicorn named Lila discovered a hidden pond that glowed with moonlight. Every night, she would leave sparkling, magical flowers by the water's edge, hoping to share her beauty with others. One enchanting evening, she woke to find a group of friendly animals gathered around, eager to be friends and share in her magic."
          }
        group: responses
        name: response.output_text.done
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.output_text.done`.
          x-stainless-const: true
          type: string
          enum:
          - response.output_text.done
        item_id:
          description: |
            The ID of the output item that the text content is finalized.
          type: string
        output_index:
          description: |
            The index of the output item that the text content is finalized.
          type: integer
        content_index:
          description: |
            The index of the content part that the text content is finalized.
          type: integer
        text:
          description: |
            The text content that is finalized.
          type: string
      required:
      - type
      - item_id
      - output_index
      - content_index
      - text
    ResponseUsage:
      description: |
        Represents token usage details including input tokens, output tokens,
        a breakdown of output tokens, and the total tokens used.
      type: object
      properties:
        input_tokens:
          description: The number of input tokens.
          type: integer
        input_tokens_details:
          description: A detailed breakdown of the input tokens.
          type: object
          properties:
            cached_tokens:
              description: "The number of tokens that were retrieved from the cache. \n[More on prompt caching](/docs/guides/prompt-caching).\n"
              type: integer
          required:
          - cached_tokens
        output_tokens:
          description: The number of output tokens.
          type: integer
        output_tokens_details:
          description: A detailed breakdown of the output tokens.
          type: object
          properties:
            reasoning_tokens:
              description: The number of reasoning tokens.
              type: integer
          required:
          - reasoning_tokens
        total_tokens:
          description: The total number of tokens used.
          type: integer
      required:
      - input_tokens
      - input_tokens_details
      - output_tokens
      - output_tokens_details
      - total_tokens
    ResponseWebSearchCallCompletedEvent:
      description: Emitted when a web search call is completed.
      x-oaiMeta:
        example: |
          {
            "type": "response.web_search_call.completed",
            "output_index": 0,
            "item_id": "ws_123",
          }
        group: responses
        name: response.web_search_call.completed
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.web_search_call.completed`.
          x-stainless-const: true
          type: string
          enum:
          - response.web_search_call.completed
        output_index:
          description: |
            The index of the output item that the web search call is associated with.
          type: integer
        item_id:
          description: |
            Unique ID for the output item associated with the web search call.
          type: string
      required:
      - type
      - output_index
      - item_id
    ResponseWebSearchCallInProgressEvent:
      description: Emitted when a web search call is initiated.
      x-oaiMeta:
        example: |
          {
            "type": "response.web_search_call.in_progress",
            "output_index": 0,
            "item_id": "ws_123",
          }
        group: responses
        name: response.web_search_call.in_progress
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.web_search_call.in_progress`.
          x-stainless-const: true
          type: string
          enum:
          - response.web_search_call.in_progress
        output_index:
          description: |
            The index of the output item that the web search call is associated with.
          type: integer
        item_id:
          description: |
            Unique ID for the output item associated with the web search call.
          type: string
      required:
      - type
      - output_index
      - item_id
    ResponseWebSearchCallSearchingEvent:
      description: Emitted when a web search call is executing.
      x-oaiMeta:
        example: |
          {
            "type": "response.web_search_call.searching",
            "output_index": 0,
            "item_id": "ws_123",
          }
        group: responses
        name: response.web_search_call.searching
      type: object
      properties:
        type:
          description: |
            The type of the event. Always `response.web_search_call.searching`.
          x-stainless-const: true
          type: string
          enum:
          - response.web_search_call.searching
        output_index:
          description: |
            The index of the output item that the web search call is associated with.
          type: integer
        item_id:
          description: |
            Unique ID for the output item associated with the web search call.
          type: string
      required:
      - type
      - output_index
      - item_id
    Screenshot:
      title: Screenshot
      description: |
        A screenshot action.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a screenshot action, this property is \nalways set to `screenshot`.\n"
          default: screenshot
          x-stainless-const: true
          type: string
          enum:
          - screenshot
      required:
      - type
    Scroll:
      title: Scroll
      description: |
        A scroll action.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a scroll action, this property is \nalways set to `scroll`.\n"
          default: scroll
          x-stainless-const: true
          type: string
          enum:
          - scroll
        x:
          description: |
            The x-coordinate where the scroll occurred.
          type: integer
        y:
          description: |
            The y-coordinate where the scroll occurred.
          type: integer
        scroll_x:
          description: |
            The horizontal scroll distance.
          type: integer
        scroll_y:
          description: |
            The vertical scroll distance.
          type: integer
      required:
      - type
      - x
      - y
      - scroll_x
      - scroll_y
    StopConfiguration:
      nullable: true
      description: |
        Up to 4 sequences where the API will stop generating further tokens. The
        returned text will not contain the stop sequence.
      oneOf:
      - nullable: true
        example: |2+

        default: <|endoftext|>
        type: string
      - type: array
        items:
          example: '["\n"]'
          type: string
        minItems: 1
        maxItems: 4
    TextResponseFormatConfiguration:
      description: "An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs, \nwhich ensures the model will match your supplied JSON schema. Learn more in the \n[Structured Outputs guide](/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n"
      x-oaiExpandable: true
      oneOf:
      - $ref: '#/components/schemas/ResponseFormatText'
      - $ref: '#/components/schemas/TextResponseFormatJsonSchema'
      - $ref: '#/components/schemas/ResponseFormatJsonObject'
    TextResponseFormatJsonSchema:
      title: JSON schema
      description: |
        JSON Schema response format. Used to generate structured JSON responses.
        Learn more about [Structured Outputs](/docs/guides/structured-outputs).
      type: object
      properties:
        type:
          description: The type of response format being defined. Always `json_schema`.
          x-stainless-const: true
          type: string
          enum:
          - json_schema
        description:
          description: |
            A description of what the response format is for, used by the model to
            determine how to respond in the format.
          type: string
        name:
          description: |
            The name of the response format. Must be a-z, A-Z, 0-9, or contain
            underscores and dashes, with a maximum length of 64.
          type: string
        schema:
          $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
        strict:
          nullable: true
          description: |
            Whether to enable strict schema adherence when generating the output.
            If set to true, the model will always follow the exact schema defined
            in the `schema` field. Only a subset of JSON Schema is supported when
            `strict` is `true`. To learn more, read the [Structured Outputs
            guide](/docs/guides/structured-outputs).
          default: false
          type: boolean
      required:
      - type
      - schema
    Tool:
      x-oaiExpandable: true
      oneOf:
      - $ref: '#/components/schemas/FileSearchTool'
      - $ref: '#/components/schemas/FunctionTool'
      - $ref: '#/components/schemas/ComputerTool'
      - $ref: '#/components/schemas/WebSearchTool'
    ToolChoiceFunction:
      title: Function tool
      description: |
        Use this option to force the model to call a specific function.
      type: object
      properties:
        type:
          description: For function calling, the type is always `function`.
          x-stainless-const: true
          type: string
          enum:
          - function
        name:
          description: The name of the function to call.
          type: string
      required:
      - type
      - name
    ToolChoiceOptions:
      title: Tool choice mode
      description: |
        Controls which (if any) tool is called by the model.

        `none` means the model will not call any tool and instead generates a message.

        `auto` means the model can pick between generating a message or calling one or
        more tools.

        `required` means the model must call one or more tools.
      type: string
      enum:
      - none
      - auto
      - required
    ToolChoiceTypes:
      title: Hosted tool
      description: |
        Indicates that the model should use a built-in tool to generate a response.
        [Learn more about built-in tools](/docs/guides/tools).
      type: object
      properties:
        type:
          description: |
            The type of hosted tool the model should to use. Learn more about
            [built-in tools](/docs/guides/tools).

            Allowed values are:
            - `file_search`
            - `web_search_preview`
            - `computer_use_preview`
          type: string
          enum:
          - file_search
          - web_search_preview
          - computer_use_preview
          - web_search_preview_2025_03_11
      required:
      - type
    Type:
      title: Type
      description: |
        An action to type in text.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a type action, this property is \nalways set to `type`.\n"
          default: type
          x-stainless-const: true
          type: string
          enum:
          - type
        text:
          description: |
            The text to type.
          type: string
      required:
      - type
      - text
    UrlCitation:
      title: URL citation
      description: |
        A citation for a web resource used to generate a model response.
      type: object
      properties:
        url:
          description: |
            The URL of the web resource.
          type: string
        title:
          description: |
            The title of the web resource.
          type: string
        type:
          description: |
            The type of the URL citation. Always `url_citation`.
          x-stainless-const: true
          type: string
          enum:
          - url_citation
        start_index:
          description: |
            The index of the first character of the URL citation in the message.
          type: integer
        end_index:
          description: |
            The index of the last character of the URL citation in the message.
          type: integer
      required:
      - url
      - title
      - type
      - start_index
      - end_index
    VectorStoreFileAttributes:
      nullable: true
      description: "Set of 16 key-value pairs that can be attached to an object. This can be \nuseful for storing additional information about the object in a structured \nformat, and querying for objects via API or the dashboard. Keys are strings \nwith a maximum length of 64 characters. Values are strings with a maximum \nlength of 512 characters, booleans, or numbers.\n"
      x-oaiTypeLabel: map
      type: object
      additionalProperties:
        oneOf:
        - type: string
          maxLength: 512
        - type: number
        - type: boolean
      maxProperties: 16
    VoiceIdsShared:
      example: ash
      anyOf:
      - type: string
      - type: string
        enum:
        - alloy
        - ash
        - ballad
        - coral
        - echo
        - fable
        - onyx
        - nova
        - sage
        - shimmer
        - verse
    Wait:
      title: Wait
      description: |
        A wait action.
      type: object
      properties:
        type:
          description: "Specifies the event type. For a wait action, this property is \nalways set to `wait`.\n"
          default: wait
          x-stainless-const: true
          type: string
          enum:
          - wait
      required:
      - type
    WebSearchContextSize:
      description: "High level guidance for the amount of context window space to use for the \nsearch. One of `low`, `medium`, or `high`. `medium` is the default.\n"
      default: medium
      type: string
      enum:
      - low
      - medium
      - high
    WebSearchLocation:
      title: Web search location
      description: Approximate location parameters for the search.
      type: object
      properties:
        country:
          description: "The two-letter \n[ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user,\ne.g. `US`.\n"
          type: string
        region:
          description: |
            Free text input for the region of the user, e.g. `California`.
          type: string
        city:
          description: |
            Free text input for the city of the user, e.g. `San Francisco`.
          type: string
        timezone:
          description: "The [IANA timezone](https://timeapi.io/documentation/iana-timezones) \nof the user, e.g. `America/Los_Angeles`.\n"
          type: string
    WebSearchTool:
      title: Web search
      description: |
        This tool searches the web for relevant results to use in a response.
        Learn more about the [web search tool](/docs/guides/tools-web-search).
      type: object
      properties:
        type:
          description: |
            The type of the web search tool. One of:
            - `web_search_preview`
            - `web_search_preview_2025_03_11`
          type: string
          enum:
          - web_search_preview
          - web_search_preview_2025_03_11
        user_location:
          nullable: true
          allOf:
          - $ref: '#/components/schemas/WebSearchLocation'
          - type: object
            properties:
              type:
                description: |
                  The type of location approximation. Always `approximate`.
                x-stainless-const: true
                type: string
                enum:
                - approximate
            required:
            - type
        search_context_size:
          $ref: '#/components/schemas/WebSearchContextSize'
      required:
      - type
    WebSearchToolCall:
      title: Web search tool call
      description: "The results of a web search tool call. See the \n[web search guide](/docs/guides/tools-web-search) for more information.\n"
      type: object
      properties:
        id:
          description: |
            The unique ID of the web search tool call.
          type: string
        type:
          description: |
            The type of the web search tool call. Always `web_search_call`.
          x-stainless-const: true
          type: string
          enum:
          - web_search_call
        status:
          description: |
            The status of the web search tool call.
          type: string
          enum:
          - in_progress
          - searching
          - completed
          - failed
      required:
      - id
      - type
      - status
  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: bearer
security:
- ApiKeyAuth: []
tags:
- name: Assistants
  description: Build Assistants that can call models and use tools.
- name: Audio
  description: Turn audio into text or text into audio.
- name: Chat
  description: Given a list of messages comprising a conversation, the model will return a response.
- name: Completions
  description: Given a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position.
- name: Embeddings
  description: Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
- name: Fine-tuning
  description: Manage fine-tuning jobs to tailor a model to your specific training data.
- name: Batch
  description: Create large batches of API requests to run asynchronously.
- name: Files
  description: Files are used to upload documents that can be used with features like Assistants and Fine-tuning.
- name: Uploads
  description: Use Uploads to upload large files in multiple parts.
- name: Images
  description: Given a prompt and/or an input image, the model will generate a new image.
- name: Models
  description: List and describe the various models available in the API.
- name: Moderations
  description: Given text and/or image inputs, classifies if those inputs are potentially harmful.
- name: Audit Logs
  description: List user actions and configuration changes within this organization.
x-oaiMeta:
  groups:
  - description: "The Chat Completions API endpoint will generate a model response from a \nlist of messages comprising a conversation.\n\nRelated guides:\n- [Quickstart](/docs/quickstart?api-mode=chat)\n- [Text inputs and outputs](/docs/guides/text?api-mode=chat)\n- [Image inputs](/docs/guides/images?api-mode=chat)\n- [Audio inputs and outputs](/docs/guides/audio?api-mode=chat)\n- [Structured Outputs](/docs/guides/structured-outputs?api-mode=chat)\n- [Function calling](/docs/guides/function-calling?api-mode=chat)\n- [Conversation state](/docs/guides/conversation-state?api-mode=chat)\n\n**Starting a new project?** We recommend trying [Responses](/docs/api-reference/responses) \nto take advantage of the latest OpenAI platform features. Compare\n[Chat Completions with Responses](/docs/guides/responses-vs-chat-completions?api-mode=responses).\n"
    id: chat
    navigationGroup: chat
    sections:
    - key: createChatCompletion
      path: create
      type: endpoint
    - key: getChatCompletion
      path: get
      type: endpoint
    - key: getChatCompletionMessages
      path: getMessages
      type: endpoint
    - key: listChatCompletions
      path: list
      type: endpoint
    - key: updateChatCompletion
      path: update
      type: endpoint
    - key: deleteChatCompletion
      path: delete
      type: endpoint
    - key: CreateChatCompletionResponse
      path: object
      type: object
    - key: ChatCompletionList
      path: list-object
      type: object
    - key: ChatCompletionMessageList
      path: message-list
      type: object
    title: Chat Completions
  - description: "Stream Chat Completions in real time. Receive chunks of completions\nreturned from the model using server-sent events. \n[Learn more](/docs/guides/streaming-responses?api-mode=chat).\n"
    id: chat-streaming
    navigationGroup: chat
    sections:
    - key: CreateChatCompletionStreamResponse
      path: streaming
      type: object
    title: Streaming
  - description: |
      Learn how to turn audio into text or text into audio.

      Related guide: [Speech to text](/docs/guides/speech-to-text)
    id: audio
    navigationGroup: endpoints
    sections:
    - key: createSpeech
      path: createSpeech
      type: endpoint
    - key: createTranscription
      path: createTranscription
      type: endpoint
    - key: createTranslation
      path: createTranslation
      type: endpoint
    - key: CreateTranscriptionResponseJson
      path: json-object
      type: object
    - key: CreateTranscriptionResponseVerboseJson
      path: verbose-json-object
      type: object
    - key: TranscriptTextDeltaEvent
      path: transcript-text-delta-event
      type: object
    - key: TranscriptTextDoneEvent
      path: transcript-text-done-event
      type: object
    title: Audio
  - description: |
      Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
      Related guide: [Embeddings](/docs/guides/embeddings)
    id: embeddings
    navigationGroup: endpoints
    sections:
    - key: createEmbedding
      path: create
      type: endpoint
    - key: Embedding
      path: object
      type: object
    title: Embeddings
  - description: |
      Manage fine-tuning jobs to tailor a model to your specific training data.
      Related guide: [Fine-tune models](/docs/guides/fine-tuning)
    id: fine-tuning
    navigationGroup: endpoints
    sections:
    - key: createFineTuningJob
      path: create
      type: endpoint
    - key: listPaginatedFineTuningJobs
      path: list
      type: endpoint
    - key: listFineTuningEvents
      path: list-events
      type: endpoint
    - key: listFineTuningJobCheckpoints
      path: list-checkpoints
      type: endpoint
    - key: listFineTuningCheckpointPermissions
      path: list-permissions
      type: endpoint
    - key: createFineTuningCheckpointPermission
      path: create-permission
      type: endpoint
    - key: deleteFineTuningCheckpointPermission
      path: delete-permission
      type: endpoint
    - key: retrieveFineTuningJob
      path: retrieve
      type: endpoint
    - key: cancelFineTuningJob
      path: cancel
      type: endpoint
    - key: FineTuneChatRequestInput
      path: chat-input
      type: object
    - key: FineTunePreferenceRequestInput
      path: preference-input
      type: object
    - key: FineTuneCompletionRequestInput
      path: completions-input
      type: object
    - key: FineTuningJob
      path: object
      type: object
    - key: FineTuningJobEvent
      path: event-object
      type: object
    - key: FineTuningJobCheckpoint
      path: checkpoint-object
      type: object
    - key: FineTuningCheckpointPermission
      path: permission-object
      type: object
    title: Fine-tuning
  - description: |
      Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
      Related guide: [Batch](/docs/guides/batch)
    id: batch
    navigationGroup: endpoints
    sections:
    - key: createBatch
      path: create
      type: endpoint
    - key: retrieveBatch
      path: retrieve
      type: endpoint
    - key: cancelBatch
      path: cancel
      type: endpoint
    - key: listBatches
      path: list
      type: endpoint
    - key: Batch
      path: object
      type: object
    - key: BatchRequestInput
      path: request-input
      type: object
    - key: BatchRequestOutput
      path: request-output
      type: object
    title: Batch
  - description: |
      Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).
    id: files
    navigationGroup: endpoints
    sections:
    - key: createFile
      path: create
      type: endpoint
    - key: listFiles
      path: list
      type: endpoint
    - key: retrieveFile
      path: retrieve
      type: endpoint
    - key: deleteFile
      path: delete
      type: endpoint
    - key: downloadFile
      path: retrieve-contents
      type: endpoint
    - key: OpenAIFile
      path: object
      type: object
    title: Files
  - description: |
      Allows you to upload large files in multiple parts.
    id: uploads
    navigationGroup: endpoints
    sections:
    - key: createUpload
      path: create
      type: endpoint
    - key: addUploadPart
      path: add-part
      type: endpoint
    - key: completeUpload
      path: complete
      type: endpoint
    - key: cancelUpload
      path: cancel
      type: endpoint
    - key: Upload
      path: object
      type: object
    - key: UploadPart
      path: part-object
      type: object
    title: Uploads
  - description: |
      Given a prompt and/or an input image, the model will generate a new image.
      Related guide: [Image generation](/docs/guides/images)
    id: images
    navigationGroup: endpoints
    sections:
    - key: createImage
      path: create
      type: endpoint
    - key: createImageEdit
      path: createEdit
      type: endpoint
    - key: createImageVariation
      path: createVariation
      type: endpoint
    - key: Image
      path: object
      type: object
    title: Images
  - description: |
      List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.
    id: models
    navigationGroup: endpoints
    sections:
    - key: listModels
      path: list
      type: endpoint
    - key: retrieveModel
      path: retrieve
      type: endpoint
    - key: deleteModel
      path: delete
      type: endpoint
    - key: Model
      path: object
      type: object
    title: Models
  - description: |
      Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
      Related guide: [Moderations](/docs/guides/moderation)
    id: moderations
    navigationGroup: endpoints
    sections:
    - key: createModeration
      path: create
      type: endpoint
    - key: CreateModerationResponse
      path: object
      type: object
    title: Moderations
  - description: "OpenAI's most advanced interface for generating model responses. Supports\ntext and image inputs, and text outputs. Create stateful interactions\nwith the model, using the output of previous responses as input. Extend\nthe model's capabilities with built-in tools for file search, web search,\ncomputer use, and more. Allow the model access to external systems and data \nusing function calling.\n\nRelated guides:\n- [Quickstart](/docs/quickstart?api-mode=responses)\n- [Text inputs and outputs](/docs/guides/text?api-mode=responses)\n- [Image inputs](/docs/guides/images?api-mode=responses)\n- [Structured Outputs](/docs/guides/structured-outputs?api-mode=responses)\n- [Function calling](/docs/guides/function-calling?api-mode=responses)\n- [Conversation state](/docs/guides/conversation-state?api-mode=responses)\n- [Extend the models with tools](/docs/guides/tools?api-mode=responses)\n"
    id: responses
    navigationGroup: responses
    sections:
    - key: createResponse
      path: create
      type: endpoint
    - key: getResponse
      path: get
      type: endpoint
    - key: deleteResponse
      path: delete
      type: endpoint
    - key: listInputItems
      path: input-items
      type: endpoint
    - key: Response
      path: object
      type: object
    - key: ResponseItemList
      path: list
      type: object
    title: Responses
  - description: |
      When you [create a Response](/docs/api-reference/responses/create) with
      `stream` set to `true`, the server will emit server-sent events to the
      client as the Response is generated. This section contains the events that
      are emitted by the server.

      [Learn more about streaming responses](/docs/guides/streaming-responses?api-mode=responses).
    id: responses-streaming
    navigationGroup: responses
    sections:
    - key: ResponseCreatedEvent
      path: <auto>
      type: object
    - key: ResponseInProgressEvent
      path: <auto>
      type: object
    - key: ResponseCompletedEvent
      path: <auto>
      type: object
    - key: ResponseFailedEvent
      path: <auto>
      type: object
    - key: ResponseIncompleteEvent
      path: <auto>
      type: object
    - key: ResponseOutputItemAddedEvent
      path: <auto>
      type: object
    - key: ResponseOutputItemDoneEvent
      path: <auto>
      type: object
    - key: ResponseContentPartAddedEvent
      path: <auto>
      type: object
    - key: ResponseContentPartDoneEvent
      path: <auto>
      type: object
    - key: ResponseTextDeltaEvent
      path: <auto>
      type: object
    - key: ResponseTextAnnotationDeltaEvent
      path: <auto>
      type: object
    - key: ResponseTextDoneEvent
      path: <auto>
      type: object
    - key: ResponseRefusalDeltaEvent
      path: <auto>
      type: object
    - key: ResponseRefusalDoneEvent
      path: <auto>
      type: object
    - key: ResponseFunctionCallArgumentsDeltaEvent
      path: <auto>
      type: object
    - key: ResponseFunctionCallArgumentsDoneEvent
      path: <auto>
      type: object
    - key: ResponseFileSearchCallInProgressEvent
      path: <auto>
      type: object
    - key: ResponseFileSearchCallSearchingEvent
      path: <auto>
      type: object
    - key: ResponseFileSearchCallCompletedEvent
      path: <auto>
      type: object
    - key: ResponseWebSearchCallInProgressEvent
      path: <auto>
      type: object
    - key: ResponseWebSearchCallSearchingEvent
      path: <auto>
      type: object
    - key: ResponseWebSearchCallCompletedEvent
      path: <auto>
      type: object
    - key: ResponseErrorEvent
      path: <auto>
      type: object
    title: Streaming
  - beta: true
    description: "Communicate with a GPT-4o class model in real time using WebRTC or \nWebSockets. Supports text and audio inputs and ouputs, along with audio\ntranscriptions.\n[Learn more about the Realtime API](/docs/guides/realtime).\n"
    id: realtime
    navigationGroup: realtime
    title: Realtime
  - description: |
      REST API endpoint to generate ephemeral session tokens for use in client-side
      applications.
    id: realtime-sessions
    navigationGroup: realtime
    sections:
    - key: create-realtime-session
      path: create
      type: endpoint
    - key: create-realtime-transcription-session
      path: create-transcription
      type: endpoint
    - key: RealtimeSessionCreateResponse
      path: session_object
      type: object
    - key: RealtimeTranscriptionSessionCreateResponse
      path: transcription_session_object
      type: object
    title: Session tokens
  - description: |
      These are events that the OpenAI Realtime WebSocket server will accept from the client.
    id: realtime-client-events
    navigationGroup: realtime
    sections:
    - key: RealtimeClientEventSessionUpdate
      path: <auto>
      type: object
    - key: RealtimeClientEventInputAudioBufferAppend
      path: <auto>
      type: object
    - key: RealtimeClientEventInputAudioBufferCommit
      path: <auto>
      type: object
    - key: RealtimeClientEventInputAudioBufferClear
      path: <auto>
      type: object
    - key: RealtimeClientEventConversationItemCreate
      path: <auto>
      type: object
    - key: RealtimeClientEventConversationItemTruncate
      path: <auto>
      type: object
    - key: RealtimeClientEventConversationItemDelete
      path: <auto>
      type: object
    - key: RealtimeClientEventResponseCreate
      path: <auto>
      type: object
    - key: RealtimeClientEventResponseCancel
      path: <auto>
      type: object
    - key: RealtimeClientEventTranscriptionSessionUpdate
      path: <auto>
      type: object
    title: Client events
  - description: |
      These are events emitted from the OpenAI Realtime WebSocket server to the client.
    id: realtime-server-events
    navigationGroup: realtime
    sections:
    - key: RealtimeServerEventError
      path: <auto>
      type: object
    - key: RealtimeServerEventSessionCreated
      path: <auto>
      type: object
    - key: RealtimeServerEventSessionUpdated
      path: <auto>
      type: object
    - key: RealtimeServerEventConversationCreated
      path: <auto>
      type: object
    - key: RealtimeServerEventConversationItemCreated
      path: <auto>
      type: object
    - key: RealtimeServerEventConversationItemInputAudioTranscriptionCompleted
      path: <auto>
      type: object
    - key: RealtimeServerEventConversationItemInputAudioTranscriptionDelta
      path: <auto>
      type: object
    - key: RealtimeServerEventConversationItemInputAudioTranscriptionFailed
      path: <auto>
      type: object
    - key: RealtimeServerEventConversationItemTruncated
      path: <auto>
      type: object
    - key: RealtimeServerEventConversationItemDeleted
      path: <auto>
      type: object
    - key: RealtimeServerEventInputAudioBufferCommitted
      path: <auto>
      type: object
    - key: RealtimeServerEventInputAudioBufferCleared
      path: <auto>
      type: object
    - key: RealtimeServerEventInputAudioBufferSpeechStarted
      path: <auto>
      type: object
    - key: RealtimeServerEventInputAudioBufferSpeechStopped
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseCreated
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseDone
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseOutputItemAdded
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseOutputItemDone
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseContentPartAdded
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseContentPartDone
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseTextDelta
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseTextDone
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseAudioTranscriptDelta
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseAudioTranscriptDone
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseAudioDelta
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseAudioDone
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseFunctionCallArgumentsDelta
      path: <auto>
      type: object
    - key: RealtimeServerEventResponseFunctionCallArgumentsDone
      path: <auto>
      type: object
    - key: RealtimeServerEventTranscriptionSessionUpdated
      path: <auto>
      type: object
    - key: RealtimeServerEventRateLimitsUpdated
      path: <auto>
      type: object
    title: Server events
  - description: |
      Vector stores power semantic search for the Retrieval API and the `file_search` tool in the Responses and Assistants APIs.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    id: vector-stores
    navigationGroup: vector_stores
    sections:
    - key: createVectorStore
      path: create
      type: endpoint
    - key: listVectorStores
      path: list
      type: endpoint
    - key: getVectorStore
      path: retrieve
      type: endpoint
    - key: modifyVectorStore
      path: modify
      type: endpoint
    - key: deleteVectorStore
      path: delete
      type: endpoint
    - key: searchVectorStore
      path: search
      type: endpoint
    - key: VectorStoreObject
      path: object
      type: object
    title: Vector stores
  - description: |
      Vector store files represent files inside a vector store.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    id: vector-stores-files
    navigationGroup: vector_stores
    sections:
    - key: createVectorStoreFile
      path: createFile
      type: endpoint
    - key: listVectorStoreFiles
      path: listFiles
      type: endpoint
    - key: getVectorStoreFile
      path: getFile
      type: endpoint
    - key: retrieveVectorStoreFileContent
      path: getContent
      type: endpoint
    - key: updateVectorStoreFileAttributes
      path: updateAttributes
      type: endpoint
    - key: deleteVectorStoreFile
      path: deleteFile
      type: endpoint
    - key: VectorStoreFileObject
      path: file-object
      type: object
    title: Vector store files
  - description: |
      Vector store file batches represent operations to add multiple files to a vector store.
      Related guide: [File Search](/docs/assistants/tools/file-search)
    id: vector-stores-file-batches
    navigationGroup: vector_stores
    sections:
    - key: createVectorStoreFileBatch
      path: createBatch
      type: endpoint
    - key: getVectorStoreFileBatch
      path: getBatch
      type: endpoint
    - key: cancelVectorStoreFileBatch
      path: cancelBatch
      type: endpoint
    - key: listFilesInVectorStoreBatch
      path: listBatchFiles
      type: endpoint
    - key: VectorStoreFileBatchObject
      path: batch-object
      type: object
    title: Vector store file batches
  - description: |
      Programmatically manage your organization.
      The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
      To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
      For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)
    id: administration
    navigationGroup: administration
    title: Administration
  - description: |
      Admin API keys enable Organization Owners to programmatically manage various aspects of their organization, including users, projects, and API keys. These keys provide administrative capabilities, such as creating, updating, and deleting users; managing projects; and overseeing API key lifecycles.

      Key Features of Admin API Keys:

      - User Management: Invite new users, update roles, and remove users from the organization.

      - Project Management: Create, update, archive projects, and manage user assignments within projects.

      - API Key Oversight: List, retrieve, and delete API keys associated with projects.

      Only Organization Owners have the authority to create and utilize Admin API keys. To manage these keys, Organization Owners can navigate to the Admin Keys section of their API Platform dashboard.

      For direct access to the Admin Keys management page, Organization Owners can use the following link:

      [https://platform.openai.com/settings/organization/admin-keys](https://platform.openai.com/settings/organization/admin-keys)

      It's crucial to handle Admin API keys with care due to their elevated permissions. Adhering to best practices, such as regular key rotation and assigning appropriate permissions, enhances security and ensures proper governance within the organization.
    id: admin-api-keys
    navigationGroup: administration
    sections:
    - key: admin-api-keys-list
      path: list
      type: endpoint
    - key: admin-api-keys-create
      path: create
      type: endpoint
    - key: admin-api-keys-get
      path: listget
      type: endpoint
    - key: admin-api-keys-delete
      path: delete
      type: endpoint
    title: Admin API Keys
  - description: Invite and manage invitations for an organization.
    id: invite
    navigationGroup: administration
    sections:
    - key: list-invites
      path: list
      type: endpoint
    - key: inviteUser
      path: create
      type: endpoint
    - key: retrieve-invite
      path: retrieve
      type: endpoint
    - key: delete-invite
      path: delete
      type: endpoint
    - key: Invite
      path: object
      type: object
    title: Invites
  - description: |
      Manage users and their role in an organization.
    id: users
    navigationGroup: administration
    sections:
    - key: list-users
      path: list
      type: endpoint
    - key: modify-user
      path: modify
      type: endpoint
    - key: retrieve-user
      path: retrieve
      type: endpoint
    - key: delete-user
      path: delete
      type: endpoint
    - key: User
      path: object
      type: object
    title: Users
  - description: |
      Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
      The Default project cannot be archived.
    id: projects
    navigationGroup: administration
    sections:
    - key: list-projects
      path: list
      type: endpoint
    - key: create-project
      path: create
      type: endpoint
    - key: retrieve-project
      path: retrieve
      type: endpoint
    - key: modify-project
      path: modify
      type: endpoint
    - key: archive-project
      path: archive
      type: endpoint
    - key: Project
      path: object
      type: object
    title: Projects
  - description: |
      Manage users within a project, including adding, updating roles, and removing users.
    id: project-users
    navigationGroup: administration
    sections:
    - key: list-project-users
      path: list
      type: endpoint
    - key: create-project-user
      path: creeate
      type: endpoint
    - key: retrieve-project-user
      path: retrieve
      type: endpoint
    - key: modify-project-user
      path: modify
      type: endpoint
    - key: delete-project-user
      path: delete
      type: endpoint
    - key: ProjectUser
      path: object
      type: object
    title: Project users
  - description: |
      Manage service accounts within a project. A service account is a bot user that is not associated with a user.
      If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
      do not have this limitation. However, service accounts can also be deleted from a project.
    id: project-service-accounts
    navigationGroup: administration
    sections:
    - key: list-project-service-accounts
      path: list
      type: endpoint
    - key: create-project-service-account
      path: create
      type: endpoint
    - key: retrieve-project-service-account
      path: retrieve
      type: endpoint
    - key: delete-project-service-account
      path: delete
      type: endpoint
    - key: ProjectServiceAccount
      path: object
      type: object
    title: Project service accounts
  - description: |
      Manage API keys for a given project. Supports listing and deleting keys for users.
      This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.
    id: project-api-keys
    navigationGroup: administration
    sections:
    - key: list-project-api-keys
      path: list
      type: endpoint
    - key: retrieve-project-api-key
      path: retrieve
      type: endpoint
    - key: delete-project-api-key
      path: delete
      type: endpoint
    - key: ProjectApiKey
      path: object
      type: object
    title: Project API keys
  - description: |
      Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.
    id: project-rate-limits
    navigationGroup: administration
    sections:
    - key: list-project-rate-limits
      path: list
      type: endpoint
    - key: update-project-rate-limits
      path: update
      type: endpoint
    - key: ProjectRateLimit
      path: object
      type: object
    title: Project rate limits
  - description: |
      Logs of user actions and configuration changes within this organization.
      To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
      Once activated, for security reasons, logging cannot be deactivated.
    id: audit-logs
    navigationGroup: administration
    sections:
    - key: list-audit-logs
      path: list
      type: endpoint
    - key: AuditLog
      path: object
      type: object
    title: Audit logs
  - description: |
      The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

      While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.
    id: usage
    navigationGroup: administration
    sections:
    - key: usage-completions
      path: completions
      type: endpoint
    - key: UsageCompletionsResult
      path: completions_object
      type: object
    - key: usage-embeddings
      path: embeddings
      type: endpoint
    - key: UsageEmbeddingsResult
      path: embeddings_object
      type: object
    - key: usage-moderations
      path: moderations
      type: endpoint
    - key: UsageModerationsResult
      path: moderations_object
      type: object
    - key: usage-images
      path: images
      type: endpoint
    - key: UsageImagesResult
      path: images_object
      type: object
    - key: usage-audio-speeches
      path: audio_speeches
      type: endpoint
    - key: UsageAudioSpeechesResult
      path: audio_speeches_object
      type: object
    - key: usage-audio-transcriptions
      path: audio_transcriptions
      type: endpoint
    - key: UsageAudioTranscriptionsResult
      path: audio_transcriptions_object
      type: object
    - key: usage-vector-stores
      path: vector_stores
      type: endpoint
    - key: UsageVectorStoresResult
      path: vector_stores_object
      type: object
    - key: usage-code-interpreter-sessions
      path: code_interpreter_sessions
      type: endpoint
    - key: UsageCodeInterpreterSessionsResult
      path: code_interpreter_sessions_object
      type: object
    - key: usage-costs
      path: costs
      type: endpoint
    - key: CostsResult
      path: costs_object
      type: object
    title: Usage
  - beta: true
    description: |
      Build assistants that can call models and use tools to perform tasks.

      [Get started with the Assistants API](/docs/assistants)
    id: assistants
    navigationGroup: assistants
    sections:
    - key: createAssistant
      path: createAssistant
      type: endpoint
    - key: listAssistants
      path: listAssistants
      type: endpoint
    - key: getAssistant
      path: getAssistant
      type: endpoint
    - key: modifyAssistant
      path: modifyAssistant
      type: endpoint
    - key: deleteAssistant
      path: deleteAssistant
      type: endpoint
    - key: AssistantObject
      path: object
      type: object
    title: Assistants
  - beta: true
    description: |
      Create threads that assistants can interact with.

      Related guide: [Assistants](/docs/assistants/overview)
    id: threads
    navigationGroup: assistants
    sections:
    - key: createThread
      path: createThread
      type: endpoint
    - key: getThread
      path: getThread
      type: endpoint
    - key: modifyThread
      path: modifyThread
      type: endpoint
    - key: deleteThread
      path: deleteThread
      type: endpoint
    - key: ThreadObject
      path: object
      type: object
    title: Threads
  - beta: true
    description: |
      Create messages within threads

      Related guide: [Assistants](/docs/assistants/overview)
    id: messages
    navigationGroup: assistants
    sections:
    - key: createMessage
      path: createMessage
      type: endpoint
    - key: listMessages
      path: listMessages
      type: endpoint
    - key: getMessage
      path: getMessage
      type: endpoint
    - key: modifyMessage
      path: modifyMessage
      type: endpoint
    - key: deleteMessage
      path: deleteMessage
      type: endpoint
    - key: MessageObject
      path: object
      type: object
    title: Messages
  - beta: true
    description: |
      Represents an execution run on a thread.

      Related guide: [Assistants](/docs/assistants/overview)
    id: runs
    navigationGroup: assistants
    sections:
    - key: createRun
      path: createRun
      type: endpoint
    - key: createThreadAndRun
      path: createThreadAndRun
      type: endpoint
    - key: listRuns
      path: listRuns
      type: endpoint
    - key: getRun
      path: getRun
      type: endpoint
    - key: modifyRun
      path: modifyRun
      type: endpoint
    - key: submitToolOuputsToRun
      path: submitToolOutputs
      type: endpoint
    - key: cancelRun
      path: cancelRun
      type: endpoint
    - key: RunObject
      path: object
      type: object
    title: Runs
  - beta: true
    description: |
      Represents the steps (model and tool calls) taken during the run.

      Related guide: [Assistants](/docs/assistants/overview)
    id: run-steps
    navigationGroup: assistants
    sections:
    - key: listRunSteps
      path: listRunSteps
      type: endpoint
    - key: getRunStep
      path: getRunStep
      type: endpoint
    - key: RunStepObject
      path: step-object
      type: object
    title: Run steps
  - beta: true
    description: |
      Stream the result of executing a Run or resuming a Run after submitting tool outputs.
      You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
      [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
      endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
      Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
      [Assistants API quickstart](/docs/assistants/overview) to learn more.
    id: assistants-streaming
    navigationGroup: assistants
    sections:
    - key: MessageDeltaObject
      path: message-delta-object
      type: object
    - key: RunStepDeltaObject
      path: run-step-delta-object
      type: object
    - key: AssistantStreamEvent
      path: events
      type: object
    title: Streaming
  - description: |
      Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.
    id: completions
    legacy: true
    navigationGroup: legacy
    sections:
    - key: createCompletion
      path: create
      type: endpoint
    - key: CreateCompletionResponse
      path: object
      type: object
    title: Completions
  navigationGroups:
  - id: chat
    title: Chat Completions
  - id: endpoints
    title: Platform APIs
  - id: responses
    title: Responses
  - id: vector_stores
    title: Vector stores
  - beta: true
    id: realtime
    title: Realtime
  - id: administration
    title: Administration
  - beta: true
    id: assistants
    title: Assistants
  - id: legacy
    title: Legacy
